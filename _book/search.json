[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Praktikum Ramon Füglister",
    "section": "",
    "text": "Preface\nDies ist die Dokumentation von Ramon Füglister zum Praktikum an der Fernuni Schweiz."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "2  Literaturverzeichnis",
    "section": "",
    "text": "Wu, Junde, Jiayuan Zhu, and Yuyuan Liu. 2025. “Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research.” arXiv. https://doi.org/10.48550/ARXIV.2502.04644."
  },
  {
    "objectID": "1_Literaturrecherche.html#aufgabe",
    "href": "1_Literaturrecherche.html#aufgabe",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.1 Aufgabe",
    "text": "1.1 Aufgabe\nGibt es in der Forschungsliteratur einen Zusammenhang von Effort und Leistung (Performance) und wenn ja, wie ist dieser Zusammenhang beschaffen (linear, polyonmial etc.)? Der Schwerpunkt der Recherche bilden die psychologischen Konstrukte kognitiver Effort und kognitive Leistung. Ein Ziel war es ausserdem die Suche soweit zu möglich mit KI Tools zu unterstützen und automatisieren."
  },
  {
    "objectID": "1_Literaturrecherche.html#mögliche-zusammenhänge",
    "href": "1_Literaturrecherche.html#mögliche-zusammenhänge",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.2 Mögliche Zusammenhänge",
    "text": "1.2 Mögliche Zusammenhänge\n\n1.2.1 1. Linearer Zusammenhang\n\nBeschreibung: Jeder zusätzliche Einheit an Aufwand führt zu einer konstanten Zunahme der Leistung. Dies ist das einfachste Modell.\nMathematische Formel: \\[ P = a + b \\cdot E \\]\n\n\\(P\\): Performance\n\\(E\\): Effort\n\\(a\\): Grundleistung (Performance bei Effort = 0)\n\\(b\\): Steigung (konstanter Leistungszuwachs pro Aufwandseinheit)\n\nTypische Einsatzbereiche: Kurzfristige, einfache Aufgaben, bei denen weder Ermüdung noch signifikante Lerneffekte oder Ressourcenlimitierungen eine Rolle spielen. Oft als erste Annäherung oder Baseline verwendet. In der Realität über längere Zeiträume oder bei komplexen Aufgaben selten haltbar.\n\n\n\n1.2.2 2. Polynomieller Zusammenhang (z. B. Quadratisch)\n\nBeschreibung: Der Leistungszuwachs pro Aufwandseinheit ist nicht konstant. Ein gängiges Beispiel ist die invertierte U-Form (quadratisch mit negativem quadratischem Term): Leistung steigt zunächst mit dem Aufwand, erreicht ein Optimum und fällt dann bei weiter steigendem Aufwand wieder ab (z. B. durch Stress, Ermüdung, Übermotivation).\nMathematische Formel (quadratisch): \\[ P = a + b \\cdot E + c \\cdot E^2 \\]\n\n\\(a\\): Grundleistung\n\\(b\\): Anfängliche Steigung\n\\(c\\): Krümmung (negativ für invertierte U-Form)\n\nTypische Einsatzbereiche: Modellierung von optimalen Anstrengungsniveaus (z. B. Yerkes-Dodson-Gesetz in der Psychologie, das einen Zusammenhang zwischen Arousal/Erregung und Leistung beschreibt), Sport, komplexe Problemlösungen, bei denen Überanstrengung kontraproduktiv ist.\n\n\n\n1.2.3 3. Exponentieller Zusammenhang\n\nBeschreibung: Die Leistung steigt überproportional mit dem Aufwand. Jede zusätzliche Aufwandseinheit führt zu einem größeren Leistungszuwachs als die vorherige.\nMathematische Formel: \\[ P = a \\cdot \\exp(b \\cdot E) \\quad \\text{oder} \\quad P = a \\cdot k^E \\quad (\\text{mit } k &gt; 1 \\text{ für Wachstum}) \\]\n\n\\(a\\): Skalierungsfaktor / Startwert\n\\(b\\) bzw. \\(k\\): Wachstumsrate\n\nTypische Einsatzbereiche: Selten für die direkte Effort-Performance-Beziehung über den gesamten Bereich, da unbegrenztes Wachstum unrealistisch ist. Eventuell zur Modellierung früher Phasen exponentiellen Lernens oder bei Netzwerkeffekten, wo mehr Einsatz (z. B. in Verbreitung) exponentielle Ergebnisse (z. B. Nutzerzahlen) bringt.\n\n\n\n1.2.4 4. Logarithmischer Zusammenhang\n\nBeschreibung: Die Leistung steigt mit dem Aufwand, aber der Zuwachs wird immer geringer (abnehmender Grenzertrag). Die ersten Aufwandseinheiten bringen den größten Leistungszuwachs.\nMathematische Formel: \\[ P = a + b \\cdot \\log(E) \\quad (\\text{wobei } E &gt; 0) \\]\n\n\\(a\\): Verschiebungsparameter\n\\(b\\): Skaliert den logarithmischen Effekt\n\nTypische Einsatzbereiche: Lernkurven (Anfänger lernen schnell, Experten brauchen viel Aufwand für kleine Verbesserungen), Skill-Akquisition, Ressourcennutzung (erste Düngergaben haben größten Effekt), generell Situationen mit Sättigungseffekten. Dies ist ein häufig in der Literatur diskutierter nicht-linearer Zusammenhang.\n\n\n\n1.2.5 5. Sigmoidaler / Logistischer Zusammenhang\n\nBeschreibung: S-förmige Kurve. Anfänglich langsamer Leistungszuwachs bei steigendem Aufwand (Initialaufwand, Einarbeitung), dann eine Phase schnellen Wachstums, gefolgt von einer Abflachung hin zu einem Leistungsplateau (Sättigung, maximale Kapazität).\nMathematische Formel (Logistische Funktion): \\[ P = \\frac{L}{1 + \\exp(-k(E - E_0))} \\]\n\n\\(L\\): Maximales Leistungsniveau (Plateau)\n\\(k\\): Steilheit der Kurve\n\\(E_0\\): Aufwandswert beim Wendepunkt (halbe maximale Leistung)\n\nTypische Einsatzbereiche: Sehr häufig zur Modellierung von Lernprozessen über die Zeit, Skill-Akquisition bei komplexen Aufgaben, Technologie-Adoption, biologische Wachstumsprozesse. Gilt als sehr plausibles Modell für viele Effort-Performance-Szenarien, da es sowohl Anlaufschwierigkeiten als auch Sättigung abbildet.\n\n\n\nWarning: Paket 'plotly' wurde unter R Version 4.3.3 erstellt\n\n\nWarning: Paket 'ggplot2' wurde unter R Version 4.3.3 erstellt\n\n\nWarning: Paket 'tidyr' wurde unter R Version 4.3.3 erstellt\n\n\n\n\n\nFigure 1.1: Interaktive Visualisierung verschiedener möglicher Zusammenhänge zwischen Effort und Performance"
  },
  {
    "objectID": "1_Literaturrecherche.html#suche-nach-forschungsliteratur.",
    "href": "1_Literaturrecherche.html#suche-nach-forschungsliteratur.",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Suche nach Forschungsliteratur.",
    "text": "1.4 Suche nach Forschungsliteratur.\nDie Literaturssuche erfolgte zunächst unsystematisch und explorativ. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools.Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen Halluzinationen zu leiden. In diesem Zusammenhang scheint es erwähnenswert, dass es vielversprechende Open Source Ansätze zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025).\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI Recherche, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchanfrage und einen Überblick über die wichtigsten Datenbanken. Berücksichtige ausschliesslich Top Journals bei der Suche.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier ist eine Strategie, um in frei verfügbaren Forschungsdatenbanken nach Workflows für AI-gestützte Recherche zu suchen, unter Berücksichtigung von Top-Journalen. 1. Kernkonzepte und Suchbegriffe (Deutsch & Englisch): AI Recherche / AI-gestützte Recherche: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing (NLP), Large Language Models (LLM), Generative AI, OpenAI, AI-assisted research, AI-powered research, computational research methods. Workflows: Workflow, methodology, process, pipeline, framework, standard operating procedure (SOP), systematic approach. Kontext (Forschungsarten): Literature review, systematic review, evidence synthesis, knowledge discovery, information retrieval, research automation, data analysis. “Deep Research”: Dieser Begriff ist nicht standardisiert. Er könnte sich auf “Deep Learning” beziehen oder einfach auf “tiefgehende/umfassende Recherche”. Wir integrieren beides. 2. Optimierte Suchanfrage (Basis für die meisten Datenbanken): Diese Anfrage kombiniert die Kernkonzepte mit Booleschen Operatoren (AND, OR) und Phrasensuche (” “). Sie ist bewusst breit gehalten, um relevante Treffer nicht auszuschließen, kann aber je nach Datenbank angepasst werden. (”Artificial Intelligence” OR “AI” OR “Machine Learning” OR “Deep Learning” OR “Natural Language Processing” OR “NLP” OR “Large Language Model” OR “LLM” OR “OpenAI” OR “Generative AI”) AND (workflow* OR methodology OR process OR pipeline OR framework OR “systematic approach”) AND (research OR “literature review” OR “systematic review” OR “knowledge discovery” OR “information retrieval” OR “evidence synthesis”) Use code with caution. Erläuterung: (A OR B OR C): Findet Dokumente, die mindestens einen der Begriffe in Klammern enthalten. AND: Verknüpft die drei Hauptkonzeptgruppen – es müssen Begriffe aus jeder Gruppe vorkommen. “Phrase”: Sucht nach der exakten Wortkombination. workflow: Sucht nach “workflow” und “workflows” (Platzhalter , falls von der Datenbank unterstützt). Variationen/Verfeinerungen: Fokus auf Assistenz: Ersetzen Sie die erste Klammer durch oder ergänzen Sie sie mit (“AI-assisted” OR “AI-powered” OR “AI-driven”). Enger gefasst (falls zu viele Treffer): Entfernen Sie allgemeinere Begriffe wie “AI” oder “research” und konzentrieren Sie sich auf spezifischere wie “Large Language Model” oder “systematic review”. 3. Wichtige frei verfügbare Forschungsdatenbanken: Hier sind die wichtigsten Datenbanken, die breit gefächert sind und/oder für Informatik/AI relevant sind. Die Einschränkung auf “Top Journals” ist bei frei verfügbaren Datenbanken oft nur indirekt oder manuell möglich. Google Scholar: Stärken: Sehr breite Abdeckung (Artikel, Preprints, Thesen, Bücher), Zitationsverfolgung, oft Links zu frei verfügbaren PDFs (auch von Top-Journalen, wenn Open Access oder über Repositorien). Schwächen: Weniger präzise Suchfilter als spezialisierte Datenbanken. Kein direkter Filter für “Top Journals”. Man muss die Zeitschrift des gefundenen Artikels selbst bewerten. Anwendung der Suche: Die obige Suchanfrage kann gut verwendet werden. Sortierung nach Relevanz oder Zitationen kann helfen, wichtige Arbeiten zu finden. PubMed Central (PMC): Stärken: Fokus auf Biomedizin und Lebenswissenschaften, aber auch Berührungspunkte mit Informatik/AI in der Bioinformatik etc. Enthält einen großen Teil frei zugänglicher Volltexte. Schwächen: Thematisch eingeschränkter als Google Scholar. Kein direkter Filter für “Top Journal”-Status, aber man kann nach spezifischen (bekannten Top-)Journalen filtern. Anwendung der Suche: Die Suchanfrage kann angepasst werden (z.B. Fokus auf medizinische Anwendungen von AI-Recherche-Workflows). arXiv.org: Stärken: Der Preprint-Server für Physik, Mathematik, Informatik (inkl. AI, ML, CL), Statistik etc. Enthält oft die aktuellsten Forschungsarbeiten, noch vor der Veröffentlichung in Journals. Viele Arbeiten landen später in Top-Journalen oder Konferenzen. Schwächen: Enthält Preprints, d.h. noch nicht final begutachtete Artikel. Kein Journal-Kontext per se. Anwendung der Suche: Die Suchanfrage ist hier sehr gut anwendbar. Fokus auf die relevanten Kategorien (cs.AI, cs.CL, cs.IR etc.). Semantic Scholar: Stärken: AI-gestützte Suchmaschine mit Fokus auf Informatik und Biomedizin. Versucht, Kontext, Einfluss und Verbindungen zwischen Papern darzustellen. Identifiziert oft frei verfügbare PDFs. Kann nach “Top Influential” sortieren. Schwächen: Kein expliziter “Top Journal”-Filter, aber die Relevanz-/Einfluss-Sortierung kann helfen. Anwendung der Suche: Die Suchanfrage kann gut verwendet werden. Die zusätzlichen Analyse-Features sind nützlich. CORE (core.ac.uk): Stärken: Aggregiert Open-Access-Inhalte aus institutionellen Repositorien und Journalen weltweit. Sehr große Datenbasis frei verfügbarer Artikel. Schwächen: Qualität der Metadaten kann variieren. Kein direkter Filter für “Top Journals”. Man muss die Quelle selbst prüfen. Anwendung der Suche: Die Suchanfrage ist hier gut anwendbar. Dimensions (App - Free Version): Stärken: Sehr breite Abdeckung (Publikationen, Grants, Patente, Clinical Trials). Gute analytische Werkzeuge und Zitationsdaten. Verlinkt oft zu freien Versionen. Schwächen: Die kostenlose Version hat Einschränkungen bei Export und Analyse. Kein direkter Filter für “Top Journals”, aber man sieht die publizierende Zeitschrift. Anwendung der Suche: Die Suchanfrage kann genutzt werden. 4. Umgang mit der Einschränkung “Ausschließlich Top Journals”: Das ist die größte Herausforderung bei frei verfügbaren Datenbanken. Direkte Filter gibt es meist nicht. Vorgehensweise: Breit suchen: Verwenden Sie die obige Suchanfrage in den genannten Datenbanken (insbesondere Google Scholar, arXiv, Semantic Scholar). Ergebnisse sichten: Identifizieren Sie vielversprechende Treffer basierend auf Titel und Abstract. Journal prüfen: Notieren Sie sich bei relevanten Treffern den Namen der Zeitschrift (oder Konferenz, bei Informatik oft genauso wichtig!). Journal-Ranking verifizieren: Überprüfen Sie den Ruf/das Ranking der Zeitschrift. Dazu können Sie (falls Zugang besteht z.B. über eine Bibliothek) auf Journal Citation Reports (JCR) oder Scimago Journal Rank (SJR, frei verfügbar) zurückgreifen oder Listen von Top-Journalen im Bereich Informatik/AI konsultieren (z.B. von Universitäten oder Fachgesellschaften wie ACM/IEEE). Bei Konferenzen hilft das CORE Ranking. Fokus: Konzentrieren Sie sich auf die Artikel, die in den als “Top” identifizierten Journalen/Konferenzen erschienen sind. Zusammenfassend: Nutzen Sie die optimierte Suchanfrage als Basis. Durchsuchen Sie Google Scholar, arXiv und Semantic Scholar als primäre Quellen. Ergänzen Sie ggf. mit PMC, CORE, Dimensions. Seien Sie sich bewusst, dass die Filterung nach “Top Journals” ein manueller Nachbearbeitungsschritt ist, bei dem Sie die Publikationsorte der gefundenen relevanten Artikel selbst bewerten müssen. Viel Erfolg bei Ihrer Recherche!"
  },
  {
    "objectID": "1_Literaturrecherche.html#section",
    "href": "1_Literaturrecherche.html#section",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 ",
    "text": "1.4 \nToD: Viele interessante Papers zum Einsatz von “research workflow llm”\nhttps://www.biorxiv.org/content/10.1101/2025.02.23.639768v1.full.pdf\n(muss noch ausprobiert werden)\n\n1.4.1 Recherche mit Deep Research Tools\n\n1.4.1.1 1. Prompt für eine Anfrage zum Thema Workflow für die Recherche mit Deep Research mit AI optimieren\nZunächst wurde der Prompt für eine AI Literaturrecherche mit Google AI Studio https://aistudio.google.com/ und dem Modell “Gemini 2.5 Pro Preview 03-25” (Stand 13.04.2025) optimiert:\n\n\n\n\n\n\nVerwendeter Prompt:\n\n\n\n\n\nOptimiere meinen Prompt zum Thema KI unterstützte Literaturrecherche in der Forschung. Wie kann ich das im Jahr 2025 optimalerweise machen? Es geht darum einen perfekten Workflow für den Einsatz sämtlicher relevanten Tools (LLMs aber auch Einsatz von Python etc.) zu bekommen, inkl. möglicher Gefahren und Chancen. Der ganze Workflow muss extrem ausführlich beschrieben sein und darf niemals hypothetische Tools oder Funktionen beinhalten, sondern muss ausschliesslich auf bekannte Funktionalitäten aufsetzen. Ich brauche einen vollständigen Prompt.\n\n\n\n\n\n\n\n\n\nAI Output\n\n\n\n\n\nOkay, hier ist ein optimierter Prompt, der darauf abzielt, einen detaillierten, praxisnahen und auf bekannten Technologien basierenden Workflow für die KI-gestützte Literaturrecherche im Jahr 2025 zu generieren. Dieser Prompt ist so formuliert, dass er einer leistungsstarken KI (wie GPT-4 oder Nachfolgemodellen) gegeben werden kann, um den gewünschten Workflow zu erstellen.\n\nPrompt:\nRolle: Du bist ein Experte für Forschungsmethodik, wissenschaftliches Arbeiten und den Einsatz von künstlicher Intelligenz in der Wissenschaft, mit einem Fokus auf den Stand der Technik Anfang 2025.\nAufgabe: Erstelle einen extrem ausführlichen, schrittweisen Workflow für die Durchführung einer umfassenden Literaturrecherche in einem beliebigen Forschungsfeld unter maximaler Nutzung von KI-Tools und -Technologien, wie sie bis Anfang 2025 realistischerweise etabliert und zugänglich sind. Der Workflow muss praxisorientiert sein und sich ausschließlich auf bekannte und verfügbare Funktionalitäten stützen. Hypothetische oder zukünftige, noch nicht entwickelte Tools oder Funktionen dürfen NICHT inkludiert werden.\nZielgruppe des Workflows: Wissenschaftler und Forscher (Doktoranden, Postdocs, etablierte Forscher).\nAnforderungen an den Workflow:\n\nDetaillierungsgrad: Jeder Schritt muss sehr detailliert beschrieben werden. Was genau ist zu tun? Welche spezifischen (Typen von) Tools werden eingesetzt? Wie interagieren die Tools? Wo ist menschliches Eingreifen und kritische Bewertung unerlässlich?\nPhasen: Gliedere den Workflow logisch in die typischen Phasen einer Literaturrecherche, z. B.:\n\nPhase 1: Planung & Definition (Forschungsfrage schärfen, Suchstrategie konzipieren)\nPhase 2: Suche & Identifikation (Papers finden)\nPhase 3: Screening & Auswahl (Relevanzprüfung)\nPhase 4: Datenextraktion & Analyse (Informationen aus Papers ziehen)\nPhase 5: Synthese & Berichterstattung (Ergebnisse zusammenfassen, Lücken identifizieren)\nPhase 6: Management & Aktualisierung (Referenzen verwalten, Recherche aktuell halten)\n\nTool-Integration: Beschreibe bei jedem relevanten Schritt konkret, wie folgende Tool-Kategorien (basierend auf Stand Anfang 2025) eingesetzt werden können:\n\nLarge Language Models (LLMs): z.B. GPT-4/Nachfolger, Claude-Modelle, Gemini/Bard für Aufgaben wie Brainstorming, Keyword-Generierung, Textzusammenfassung, Umformulierung, erste Syntheseentwürfe, Query-Optimierung. Spezifiziere die genaue Anwendung und die notwendige menschliche Verifikation.\nSpezialisierte KI-Such- und Analyseplattformen: z.B. Elicit, Semantic Scholar, Scite, ResearchRabbit, Connected Papers, Litmaps. Beschreibe deren spezifische Stärken (semantische Suche, Zitationsanalyse, Visualisierung von Forschungslandschaften, Frage-Antwort-Systeme basierend auf Papers).\nKI-gestützte Screening-Tools: z.B. Funktionen in systematischer Review-Software (Rayyan, Covidence) oder dedizierte Tools, die beim Priorisieren/Screenen von Abstracts helfen (basierend auf trainierten Algorithmen).\nReferenzmanagement-Software: z.B. Zotero, Mendeley, EndNote. Beschreibe auch mögliche KI-Integrationen (sofern bis Anfang 2025 Standard), z.B. für Duplikaterkennung oder Empfehlungen.\n(Optional aber empfohlen) Python-Skripte: Beschreibe einfache, realistische Anwendungsfälle für Forscher mit grundlegenden Python-Kenntnissen, z.B. zur Automatisierung von API-Abfragen (PubMed API, Crossref API), zur Deduplizierung von Suchergebnissen, zur einfachen Textanalyse (z.B. Frequenzanalysen von Keywords) oder zur Datenaufbereitung für Visualisierungen. Nutze bekannte Bibliotheken (z.B. requests, pandas, nltk, spacy, bibtexparser).\nTraditionelle Datenbanken: Betone, dass PubMed, Scopus, Web of Science etc. weiterhin essenziell sind und wie KI-Tools die Suche ergänzen, aber nicht ersetzen.\n\nChancen und Gefahren: Gehe bei jedem Schritt oder zumindest bei jeder Phase explizit und detailliert auf die spezifischen Chancen (z.B. Effizienzsteigerung, breitere Abdeckung, neue Einsichten) und Gefahren/Risiken (z.B. Halluzinationen von LLMs, Bias in Algorithmen, Verlust kritischer Fähigkeiten, Reproduzierbarkeitsprobleme, Datenschutz, “Filterblasen”-Effekte) des jeweiligen KI-Einsatzes ein. Gib konkrete Mitigationsstrategien an, wie Forscher diesen Gefahren begegnen können (z.B. Verifikationsprotokolle, Nutzung mehrerer Tools, kritische manuelle Prüfung).\nPraxisnähe und Reproduzierbarkeit: Der Workflow muss praktisch umsetzbar sein. Gib Hinweise zur Dokumentation des Vorgehens (welche Tools, Versionen, Prompts wurden verwendet?), um die Nachvollziehbarkeit zu gewährleisten.\nKeine Hypothetik: Stelle sicher, dass alle beschriebenen Tools und Funktionalitäten auf dem real existierenden Stand von Anfang 2025 basieren. Vermeide Aussagen wie “In Zukunft wird es möglich sein…” oder “Ein hypothetisches Tool könnte…”. Beziehe dich auf das, was bekannt ist.\nOutput-Format: Strukturiere die Antwort klar und übersichtlich, idealerweise mit nummerierten Schritten innerhalb der Phasen und klaren Unterabschnitten für Tools, Chancen, Gefahren und Mitigation pro Schritt/Phase.\n\nZusammenfassend: Erzeuge den bestmöglichen, detaillierten und realistischen Workflow für KI-gestützte Literaturrecherche (Stand Anfang 2025), der Forschern als praktische Anleitung dient und dabei Chancen und Risiken klar benennt und adressiert. Der Fokus liegt auf der Integration und dem Zusammenspiel bekannter Tools und Techniken.\n\nWarum dieser Prompt optimiert ist:\n\nKlare Rolle und Kontext: Definiert die Expertise der KI und den Zeitrahmen (Anfang 2025).\nSpezifische Anforderungen: Listet detailliert auf, was der Workflow enthalten muss (Phasen, Tool-Typen, Chancen/Gefahren, Detailgrad).\nFokus auf Realismus: Die Einschränkung “ausschließlich bekannte Funktionalitäten” und “keine Hypothetik” ist explizit und mehrfach genannt, um unrealistische Ergebnisse zu vermeiden.\nKonkrete Tool-Beispiele: Nennt Beispiele für jede Tool-Kategorie, um der KI eine klare Vorstellung zu geben, ohne sich auf nur ein Tool festzulegen.\nIntegration von Chancen/Gefahren: Fordert die Einbettung dieser Aspekte direkt in den Workflow, nicht nur als separaten Anhang. Verlangt auch Mitigationsstrategien.\nBetonung von Praxisnähe und Reproduzierbarkeit: Wichtige Aspekte für wissenschaftliches Arbeiten.\nStrukturvorgabe: Hilft der KI, einen gut organisierten Output zu liefern.\nZielgruppenorientierung: Stellt sicher, dass der Workflow für Forscher relevant ist.\n\nDieser Prompt sollte eine KI dazu bringen, einen sehr umfassenden und nützlichen Workflow zu generieren, der deinen Anforderungen entspricht."
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-ai-optimieren",
    "href": "1_Literaturrecherche.html#recherche-mit-ai-optimieren",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.6 Recherche mit AI optimieren",
    "text": "1.6 Recherche mit AI optimieren\nhttps://openai.com/index/introducing-deep-research/\nZunächst habe ich den Prompt für eine AI Literaturrecherche mit Google AI Studio https://aistudio.google.com/ und dem Modell “Gemini 2.5 Pro Preview 03-25” (Stand 13.04.2025) optimiert:\n\n\n\n\n\n\nVerwendeter Prompt:\n\n\n\n\n\nOptimiere meinen Prompt zum Thema KI unterstützte Literaturrecherche in der Forschung. Wie kann ich das im Jahr 2025 optimalerweise machen? Es geht darum einen perfekten Workflow für den Einsatz sämtlicher relevanten Tools (LLMs aber auch Einsatz von Python etc.) zu bekommen, inkl. möglicher Gefahren und Chancen. Der ganze Workflow muss extrem ausführlich beschrieben sein und darf niemals hypothetische Tools oder Funktionen beinhalten, sondern muss ausschliesslich auf bekannte Funktionalitäten aufsetzen. Ich brauche einen vollständigen Prompt.\n\n\n\n\n\n\n\n\n\nAI Output\n\n\n\n\n\nOkay, hier ist ein optimierter Prompt, der darauf abzielt, einen detaillierten, praxisnahen und auf bekannten Technologien basierenden Workflow für die KI-gestützte Literaturrecherche im Jahr 2025 zu generieren. Dieser Prompt ist so formuliert, dass er einer leistungsstarken KI (wie GPT-4 oder Nachfolgemodellen) gegeben werden kann, um den gewünschten Workflow zu erstellen.\n\nPrompt:\nRolle: Du bist ein Experte für Forschungsmethodik, wissenschaftliches Arbeiten und den Einsatz von künstlicher Intelligenz in der Wissenschaft, mit einem Fokus auf den Stand der Technik Anfang 2025.\nAufgabe: Erstelle einen extrem ausführlichen, schrittweisen Workflow für die Durchführung einer umfassenden Literaturrecherche in einem beliebigen Forschungsfeld unter maximaler Nutzung von KI-Tools und -Technologien, wie sie bis Anfang 2025 realistischerweise etabliert und zugänglich sind. Der Workflow muss praxisorientiert sein und sich ausschließlich auf bekannte und verfügbare Funktionalitäten stützen. Hypothetische oder zukünftige, noch nicht entwickelte Tools oder Funktionen dürfen NICHT inkludiert werden.\nZielgruppe des Workflows: Wissenschaftler und Forscher (Doktoranden, Postdocs, etablierte Forscher).\nAnforderungen an den Workflow:\n\nDetaillierungsgrad: Jeder Schritt muss sehr detailliert beschrieben werden. Was genau ist zu tun? Welche spezifischen (Typen von) Tools werden eingesetzt? Wie interagieren die Tools? Wo ist menschliches Eingreifen und kritische Bewertung unerlässlich?\nPhasen: Gliedere den Workflow logisch in die typischen Phasen einer Literaturrecherche, z. B.:\n\nPhase 1: Planung & Definition (Forschungsfrage schärfen, Suchstrategie konzipieren)\nPhase 2: Suche & Identifikation (Papers finden)\nPhase 3: Screening & Auswahl (Relevanzprüfung)\nPhase 4: Datenextraktion & Analyse (Informationen aus Papers ziehen)\nPhase 5: Synthese & Berichterstattung (Ergebnisse zusammenfassen, Lücken identifizieren)\nPhase 6: Management & Aktualisierung (Referenzen verwalten, Recherche aktuell halten)\n\nTool-Integration: Beschreibe bei jedem relevanten Schritt konkret, wie folgende Tool-Kategorien (basierend auf Stand Anfang 2025) eingesetzt werden können:\n\nLarge Language Models (LLMs): z.B. GPT-4/Nachfolger, Claude-Modelle, Gemini/Bard für Aufgaben wie Brainstorming, Keyword-Generierung, Textzusammenfassung, Umformulierung, erste Syntheseentwürfe, Query-Optimierung. Spezifiziere die genaue Anwendung und die notwendige menschliche Verifikation.\nSpezialisierte KI-Such- und Analyseplattformen: z.B. Elicit, Semantic Scholar, Scite, ResearchRabbit, Connected Papers, Litmaps. Beschreibe deren spezifische Stärken (semantische Suche, Zitationsanalyse, Visualisierung von Forschungslandschaften, Frage-Antwort-Systeme basierend auf Papers).\nKI-gestützte Screening-Tools: z.B. Funktionen in systematischer Review-Software (Rayyan, Covidence) oder dedizierte Tools, die beim Priorisieren/Screenen von Abstracts helfen (basierend auf trainierten Algorithmen).\nReferenzmanagement-Software: z.B. Zotero, Mendeley, EndNote. Beschreibe auch mögliche KI-Integrationen (sofern bis Anfang 2025 Standard), z.B. für Duplikaterkennung oder Empfehlungen.\n(Optional aber empfohlen) Python-Skripte: Beschreibe einfache, realistische Anwendungsfälle für Forscher mit grundlegenden Python-Kenntnissen, z.B. zur Automatisierung von API-Abfragen (PubMed API, Crossref API), zur Deduplizierung von Suchergebnissen, zur einfachen Textanalyse (z.B. Frequenzanalysen von Keywords) oder zur Datenaufbereitung für Visualisierungen. Nutze bekannte Bibliotheken (z.B. requests, pandas, nltk, spacy, bibtexparser).\nTraditionelle Datenbanken: Betone, dass PubMed, Scopus, Web of Science etc. weiterhin essenziell sind und wie KI-Tools die Suche ergänzen, aber nicht ersetzen.\n\nChancen und Gefahren: Gehe bei jedem Schritt oder zumindest bei jeder Phase explizit und detailliert auf die spezifischen Chancen (z.B. Effizienzsteigerung, breitere Abdeckung, neue Einsichten) und Gefahren/Risiken (z.B. Halluzinationen von LLMs, Bias in Algorithmen, Verlust kritischer Fähigkeiten, Reproduzierbarkeitsprobleme, Datenschutz, “Filterblasen”-Effekte) des jeweiligen KI-Einsatzes ein. Gib konkrete Mitigationsstrategien an, wie Forscher diesen Gefahren begegnen können (z.B. Verifikationsprotokolle, Nutzung mehrerer Tools, kritische manuelle Prüfung).\nPraxisnähe und Reproduzierbarkeit: Der Workflow muss praktisch umsetzbar sein. Gib Hinweise zur Dokumentation des Vorgehens (welche Tools, Versionen, Prompts wurden verwendet?), um die Nachvollziehbarkeit zu gewährleisten.\nKeine Hypothetik: Stelle sicher, dass alle beschriebenen Tools und Funktionalitäten auf dem real existierenden Stand von Anfang 2025 basieren. Vermeide Aussagen wie “In Zukunft wird es möglich sein…” oder “Ein hypothetisches Tool könnte…”. Beziehe dich auf das, was bekannt ist.\nOutput-Format: Strukturiere die Antwort klar und übersichtlich, idealerweise mit nummerierten Schritten innerhalb der Phasen und klaren Unterabschnitten für Tools, Chancen, Gefahren und Mitigation pro Schritt/Phase.\n\nZusammenfassend: Erzeuge den bestmöglichen, detaillierten und realistischen Workflow für KI-gestützte Literaturrecherche (Stand Anfang 2025), der Forschern als praktische Anleitung dient und dabei Chancen und Risiken klar benennt und adressiert. Der Fokus liegt auf der Integration und dem Zusammenspiel bekannter Tools und Techniken.\n\nWarum dieser Prompt optimiert ist:\n\nKlare Rolle und Kontext: Definiert die Expertise der KI und den Zeitrahmen (Anfang 2025).\nSpezifische Anforderungen: Listet detailliert auf, was der Workflow enthalten muss (Phasen, Tool-Typen, Chancen/Gefahren, Detailgrad).\nFokus auf Realismus: Die Einschränkung “ausschließlich bekannte Funktionalitäten” und “keine Hypothetik” ist explizit und mehrfach genannt, um unrealistische Ergebnisse zu vermeiden.\nKonkrete Tool-Beispiele: Nennt Beispiele für jede Tool-Kategorie, um der KI eine klare Vorstellung zu geben, ohne sich auf nur ein Tool festzulegen.\nIntegration von Chancen/Gefahren: Fordert die Einbettung dieser Aspekte direkt in den Workflow, nicht nur als separaten Anhang. Verlangt auch Mitigationsstrategien.\nBetonung von Praxisnähe und Reproduzierbarkeit: Wichtige Aspekte für wissenschaftliches Arbeiten.\nStrukturvorgabe: Hilft der KI, einen gut organisierten Output zu liefern.\nZielgruppenorientierung: Stellt sicher, dass der Workflow für Forscher relevant ist.\n\nDieser Prompt sollte eine KI dazu bringen, einen sehr umfassenden und nützlichen Workflow zu generieren, der deinen Anforderungen entspricht."
  },
  {
    "objectID": "1_Literaturrecherche.html#workflow-erstellen",
    "href": "1_Literaturrecherche.html#workflow-erstellen",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Workflow erstellen",
    "text": "1.4 Workflow erstellen\n\n\n\n\n\n\nVerwendeter Prompt:\n\n\n\n\n\nRolle: Du bist ein Experte für Forschungsmethodik, wissenschaftliches Arbeiten und den Einsatz von künstlicher Intelligenz in der Wissenschaft, mit einem Fokus auf den Stand der Technik Anfang 2025. Aufgabe: Erstelle einen extrem ausführlichen, schrittweisen Workflow für die Durchführung einer umfassenden Literaturrecherche in einem beliebigen Forschungsfeld unter maximaler Nutzung von KI-Tools und -Technologien, wie sie bis Anfang 2025 realistischerweise etabliert und zugänglich sind. Der Workflow muss praxisorientiert sein und sich ausschließlich auf bekannte und verfügbare Funktionalitäten stützen. Hypothetische oder zukünftige, noch nicht entwickelte Tools oder Funktionen dürfen NICHT inkludiert werden. Zielgruppe des Workflows: Wissenschaftler und Forscher (Doktoranden, Postdocs, etablierte Forscher). Anforderungen an den Workflow: Detaillierungsgrad: Jeder Schritt muss sehr detailliert beschrieben werden. Was genau ist zu tun? Welche spezifischen (Typen von) Tools werden eingesetzt? Wie interagieren die Tools? Wo ist menschliches Eingreifen und kritische Bewertung unerlässlich? Phasen: Gliedere den Workflow logisch in die typischen Phasen einer Literaturrecherche, z. B.: Phase 1: Planung & Definition (Forschungsfrage schärfen, Suchstrategie konzipieren) Phase 2: Suche & Identifikation (Papers finden) Phase 3: Screening & Auswahl (Relevanzprüfung) Phase 4: Datenextraktion & Analyse (Informationen aus Papers ziehen) Phase 5: Synthese & Berichterstattung (Ergebnisse zusammenfassen, Lücken identifizieren) Phase 6: Management & Aktualisierung (Referenzen verwalten, Recherche aktuell halten) Tool-Integration: Beschreibe bei jedem relevanten Schritt konkret, wie folgende Tool-Kategorien (basierend auf Stand Anfang 2025) eingesetzt werden können: Large Language Models (LLMs): z.B. GPT-4/Nachfolger, Claude-Modelle, Gemini/Bard für Aufgaben wie Brainstorming, Keyword-Generierung, Textzusammenfassung, Umformulierung, erste Syntheseentwürfe, Query-Optimierung. Spezifiziere die genaue Anwendung und die notwendige menschliche Verifikation. Spezialisierte KI-Such- und Analyseplattformen: z.B. Elicit, Semantic Scholar, Scite, ResearchRabbit, Connected Papers, Litmaps. Beschreibe deren spezifische Stärken (semantische Suche, Zitationsanalyse, Visualisierung von Forschungslandschaften, Frage-Antwort-Systeme basierend auf Papers). KI-gestützte Screening-Tools: z.B. Funktionen in systematischer Review-Software (Rayyan, Covidence) oder dedizierte Tools, die beim Priorisieren/Screenen von Abstracts helfen (basierend auf trainierten Algorithmen). Referenzmanagement-Software: z.B. Zotero, Mendeley, EndNote. Beschreibe auch mögliche KI-Integrationen (sofern bis Anfang 2025 Standard), z.B. für Duplikaterkennung oder Empfehlungen. (Optional aber empfohlen) Python-Skripte: Beschreibe einfache, realistische Anwendungsfälle für Forscher mit grundlegenden Python-Kenntnissen, z.B. zur Automatisierung von API-Abfragen (PubMed API, Crossref API), zur Deduplizierung von Suchergebnissen, zur einfachen Textanalyse (z.B. Frequenzanalysen von Keywords) oder zur Datenaufbereitung für Visualisierungen. Nutze bekannte Bibliotheken (z.B. requests, pandas, nltk, spacy, bibtexparser). Traditionelle Datenbanken: Betone, dass PubMed, Scopus, Web of Science etc. weiterhin essenziell sind und wie KI-Tools die Suche ergänzen, aber nicht ersetzen. Chancen und Gefahren: Gehe bei jedem Schritt oder zumindest bei jeder Phase explizit und detailliert auf die spezifischen Chancen (z.B. Effizienzsteigerung, breitere Abdeckung, neue Einsichten) und Gefahren/Risiken (z.B. Halluzinationen von LLMs, Bias in Algorithmen, Verlust kritischer Fähigkeiten, Reproduzierbarkeitsprobleme, Datenschutz, “Filterblasen”-Effekte) des jeweiligen KI-Einsatzes ein. Gib konkrete Mitigationsstrategien an, wie Forscher diesen Gefahren begegnen können (z.B. Verifikationsprotokolle, Nutzung mehrerer Tools, kritische manuelle Prüfung). Praxisnähe und Reproduzierbarkeit: Der Workflow muss praktisch umsetzbar sein. Gib Hinweise zur Dokumentation des Vorgehens (welche Tools, Versionen, Prompts wurden verwendet?), um die Nachvollziehbarkeit zu gewährleisten. Keine Hypothetik: Stelle sicher, dass alle beschriebenen Tools und Funktionalitäten auf dem real existierenden Stand von Anfang 2025 basieren. Vermeide Aussagen wie “In Zukunft wird es möglich sein…” oder “Ein hypothetisches Tool könnte…”. Beziehe dich auf das, was bekannt ist. Output-Format: Strukturiere die Antwort klar und übersichtlich, idealerweise mit nummerierten Schritten innerhalb der Phasen und klaren Unterabschnitten für Tools, Chancen, Gefahren und Mitigation pro Schritt/Phase. Zusammenfassend: Erzeuge den bestmöglichen, detaillierten und realistischen Workflow für KI-gestützte Literaturrecherche (Stand Anfang 2025), der Forschern als praktische Anleitung dient und dabei Chancen und Risiken klar benennt und adressiert. Der Fokus liegt auf der Integration und dem Zusammenspiel bekannter Tools und Techniken."
  },
  {
    "objectID": "1_Literaturrecherche.html#resultat",
    "href": "1_Literaturrecherche.html#resultat",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.2 Resultat",
    "text": "1.2 Resultat\nDer fertige Report ist hier verfügbar."
  },
  {
    "objectID": "1_Literaturrecherche.html#vorgehen",
    "href": "1_Literaturrecherche.html#vorgehen",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.3 Vorgehen",
    "text": "1.3 Vorgehen\n\n1.3.1 Eigene Suche nach Forschungsliteratur zum Thema KI unterstützte Suche nach Forschungsliteratur\nDie Literatursuche erfolgte zunächst unsystematisch und explorativ in einem Scoping Prozess. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. In diesem Scoping Prozess scheinen auch die besonderen Stärken der KI zu liegen (Gusenbauer & Gauster, 2025). Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung radikal zu verändern (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es auch vielversprechende Open Source Ansätze in diesem Bereich zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025). In einem nächsten Schritt des Scoping Prozesses, wurde versucht die Suchbegriffe etwas zu verfeinern, dazu wurde folgender Prompt verwendet in Google AI Studio.\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI unterstützte Recherche aber auch konkreten Tools wie “ChatGPT”, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchparameter für Google Scholar und ähnliche Suchmaschinen als praktische Tabelle (verschiedene Alternativssuchmöglichkeiten) und anschliessend einen Überblick über die wichtigsten Datenbanken, die ich mir anschauen sollte.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier sind optimierte Suchparameter und eine Übersicht über relevante Forschungsdatenbanken für Ihre Suche nach Workflows und Tools im Bereich KI-unterstützte Recherche.\n1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\n\n\n\n\n\n\n\n\nFokus / Ziel\nSuchbegriffe (Beispiele für Google Scholar & Co.)\nHinweise / Strategie\n\n\nBreit: KI & Recherche allgemein\n“artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review”\nStartpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten.\n\n\nFokus: KI-Unterstützung im Workflow\n“AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review”\nKonzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews.\n\n\nFokus: Generative KI / LLMs in Recherche\n“Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery”\nZielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen.\n\n\nSpezifisch: ChatGPT in Recherche\n“ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”)\nSucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen.\n\n\nSpezifisch: OpenAI (als Technologiegeber)\n“OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”)\nVorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research”\n\n\nSpezifisch: Andere Tools (Beispiel)\n“Deep Research” AND “AI” AND (“research tool” OR “literature review”)\nErsetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung.\n\n\nFokus: KI-Tools für Recherche\n“AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform”\nSucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung.\n\n\nKombination: Workflow & Spezifisches Tool\n(“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”)\nKombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools.\n\n\nAlternative Formulierungen\n“intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search”\nFängt alternative Bezeichnungen und Konzepte auf.\n\n\n\nWichtige Tipps zur Suche:\n\n**Anführungszeichen (” “):** Verwenden Sie sie für exakte Phrasen (z.B.”literature review”).\nOR Operator: Muss oft großgeschrieben werden. Dient zur Suche nach Alternativen (z.B. AI OR “artificial intelligence”). Klammern () können zur Gruppierung genutzt werden: (AI OR “artificial intelligence”) AND (“literature review” OR “research workflow”).\nAND Operator: Verbindet verschiedene Konzepte. Oft implizit (Leerzeichen genügt).\nPlatzhalter (*): Manche Datenbanken erlauben Wildcards (z.B. research* findet research, researcher, researching). Mit Vorsicht verwenden, kann unspezifisch werden.\nFilter nutzen: Fast alle Datenbanken erlauben Filter nach Publikationsdatum (sehr wichtig bei diesem schnelllebigen Thema!), Dokumenttyp (Journal Article, Conference Paper, Review etc.), Fachgebiet etc. Nutzen Sie insbesondere den Datumsfilter (z.B. letzte 1-3 Jahre).\nVariieren: Keine einzelne Suche ist perfekt. Probieren Sie verschiedene Kombinationen aus.\n\n2. Wichtige frei verfügbare Forschungsdatenbanken\nHier ist eine Liste der wichtigsten Datenbanken, wobei der “freie Zugang” oft bedeutet, dass die Suche und Abstracts frei sind, der Volltext aber hinter einer Paywall liegen kann (oft über Universitäts-/Institutionsbibliotheken zugänglich).\n\n\n\n\n\n\n\n\n\nDatenbank\nFokus / Beschreibung\nZugang\nRelevanz für Ihr Thema\n\n\nGoogle Scholar\nSehr breite Abdeckung über alle Disziplinen, inklusive Preprints, Konferenzbeiträge, Thesen. Einfache Suche, gute Zitationsverfolgung.\nFrei zugänglich (Suche & Abstracts). Volltexte oft verlinkt (manchmal frei, manchmal Paywall).\nSehr hoch. Exzellenter Startpunkt, findet viel, auch Graue Literatur und Preprints. Qualitätskontrolle ist aber geringer als bei kuratierten Datenbanken.\n\n\narXiv.org\nDer Preprint-Server für Physik, Mathematik, Informatik (CS), Statistik, Elektrotechnik, Quantitative Biologie, Quantitative Finanzwissenschaften.\nVöllig frei zugänglich (Suche & Volltexte).\nSehr hoch. Hier werden die meisten bahnbrechenden Arbeiten im Bereich KI/ML zuerst veröffentlicht (als Preprints). Unverzichtbar für aktuelle Forschung, insbesondere aus der Informatik.\n\n\nPubMed Central (PMC)\nArchiv für biomedizinische und biowissenschaftliche Literatur. Enthält viele frei verfügbare Volltexte.\nVöllig frei zugänglich (Suche & viele Volltexte).\nMittel bis Hoch. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bereich Medizin/Biowissenschaften untersuchen wollen. PubMed (die Suchmaschine) ist ebenfalls frei, verlinkt aber auch auf nicht-freie Artikel.\n\n\nCORE\nAggregiert Open-Access-Forschungspapiere aus Repositorien und Zeitschriften weltweit.\nFrei zugänglich (Suche & Volltexte).\nHoch. Gute Quelle, um gezielt nach frei verfügbaren Volltexten zu suchen.\n\n\nDimensions\nUmfassende Datenbank, die Publikationen, Grants, Patente, klinische Studien etc. verknüpft. Bietet eine großzügige kostenlose Version.\nKostenlose Version verfügbar (Suche & Abstracts, einige Analysen). Erweiterte Funktionen sind kostenpflichtig.\nHoch. Bietet einen breiteren Kontext als nur Publikationen. Die kostenlose Version ist sehr leistungsfähig für die Recherche und das Finden relevanter Arbeiten.\n\n\nSemantic Scholar\nKI-gestützte Forschungsdatenbank, fokussiert auf Informatik und Biomedizin, expandiert aber. Bietet Zusammenfassungen und Zitationskontext.\nFrei zugänglich (Suche & Abstracts).\nHoch. Nutzt selbst KI zur Analyse von Papern, kann daher interessante Verbindungen aufzeigen. Gute Abdeckung im CS-Bereich.\n\n\nDBLP\nFokussiert auf Informatik-Publikationen (Konferenzen & Journale). Gut strukturiert nach Autoren und Publikationsorten.\nFrei zugänglich (Suche & Metadaten, oft Links zu Volltexten).\nHoch. Wenn der Fokus stark auf der Informatik-Perspektive liegt (Algorithmen, Systembau etc.).\n\n\nERIC (Education Resources Information Center)\nFührende Datenbank für Bildungsforschung.\nFrei zugänglich (Suche & viele Volltexte).\nMittel. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bildungskontext oder in der pädagogischen Forschung untersuchen.\n\n\nSSRN (Social Science Research Network)\nPreprint-Server primär für Sozial- und Geisteswissenschaften, aber auch andere Bereiche.\nFrei zugänglich (Suche & die meisten Volltexte).\nMittel. Kann relevant sein für Anwendungsfälle in den Sozialwissenschaften oder Diskussionen über die Auswirkungen von KI auf die Forschungspraxis in diesen Feldern.\n\n\n\nWichtiger Hinweis zu “frei verfügbar”:\n\nViele der “besten” kuratierten Datenbanken wie Scopus und Web of Science sind abonnementbasiert. Wenn Sie Zugang über eine Universität, Forschungseinrichtung oder Bibliothek haben, sollten Sie diese unbedingt ebenfalls nutzen, da sie oft eine höhere Qualitätssicherung und bessere Analysefunktionen bieten.\nInstitutionelle Repositorien: Viele Universitäten haben eigene Online-Archive (Repositorien), in denen Publikationen ihrer Forscher frei zugänglich sind. Diese sind oft über Google Scholar auffindbar, können aber auch direkt durchsucht werden.\n\nEmpfohlene Vorgehensweise:\n\nStarten Sie breit mit Google Scholar und arXiv, um ein Gefühl für die aktuelle Forschung zu bekommen.\nNutzen Sie spezifischere Suchbegriffe (aus der Tabelle) in diesen und anderen Datenbanken wie Dimensions oder Semantic Scholar.\nFiltern Sie nach Datum (z.B. Veröffentlichungen seit 2022 oder 2023).\nPrüfen Sie die Abstracts auf Relevanz.\nNutzen Sie die Zitationsverfolgung: Schauen Sie, welche neueren Arbeiten relevante ältere Paper zitieren (“Cited by” in Google Scholar) und welche Paper in den gefundenen Artikeln zitiert werden (Referenzliste, “Snowballing”).\nWenn Sie Zugang haben: Wiederholen Sie die wichtigsten Suchen in Scopus und/oder Web of Science.\n\nViel Erfolg bei Ihrer Recherche!"
  },
  {
    "objectID": "1_Literaturrecherche.html#linearer-zusammenhang",
    "href": "1_Literaturrecherche.html#linearer-zusammenhang",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Linearer Zusammenhang",
    "text": "1.4 Linearer Zusammenhang\n\nBeschreibung: Jeder zusätzliche Einheit an Aufwand führt zu einer konstanten Zunahme der Leistung. Dies ist das einfachste Modell.\nMathematische Formel: \\[ P = a + b \\cdot E \\]\n\n\\(P\\): Performance\n\\(E\\): Effort\n\\(a\\): Grundleistung (Performance bei Effort = 0)\n\\(b\\): Steigung (konstanter Leistungszuwachs pro Aufwandseinheit)\n\nTypische Einsatzbereiche: Kurzfristige, einfache Aufgaben, bei denen weder Ermüdung noch signifikante Lerneffekte oder Ressourcenlimitierungen eine Rolle spielen. Oft als erste Annäherung oder Baseline verwendet. In der Realität über längere Zeiträume oder bei komplexen Aufgaben selten haltbar.\n\n\n1.4.1 2. Polynomieller Zusammenhang (z. B. Quadratisch)\n\nBeschreibung: Der Leistungszuwachs pro Aufwandseinheit ist nicht konstant. Ein gängiges Beispiel ist die invertierte U-Form (quadratisch mit negativem quadratischem Term): Leistung steigt zunächst mit dem Aufwand, erreicht ein Optimum und fällt dann bei weiter steigendem Aufwand wieder ab (z. B. durch Stress, Ermüdung, Übermotivation).\nMathematische Formel (quadratisch): \\[ P = a + b \\cdot E + c \\cdot E^2 \\]\n\n\\(a\\): Grundleistung\n\\(b\\): Anfängliche Steigung\n\\(c\\): Krümmung (negativ für invertierte U-Form)\n\nTypische Einsatzbereiche: Modellierung von optimalen Anstrengungsniveaus (z. B. Yerkes-Dodson-Gesetz in der Psychologie, das einen Zusammenhang zwischen Arousal/Erregung und Leistung beschreibt), Sport, komplexe Problemlösungen, bei denen Überanstrengung kontraproduktiv ist.\n\n\n\n1.4.2 3. Exponentieller Zusammenhang\n\nBeschreibung: Die Leistung steigt überproportional mit dem Aufwand. Jede zusätzliche Aufwandseinheit führt zu einem größeren Leistungszuwachs als die vorherige.\nMathematische Formel: \\[ P = a \\cdot \\exp(b \\cdot E) \\quad \\text{oder} \\quad P = a \\cdot k^E \\quad (\\text{mit } k &gt; 1 \\text{ für Wachstum}) \\]\n\n\\(a\\): Skalierungsfaktor / Startwert\n\\(b\\) bzw. \\(k\\): Wachstumsrate\n\nTypische Einsatzbereiche: Selten für die direkte Effort-Performance-Beziehung über den gesamten Bereich, da unbegrenztes Wachstum unrealistisch ist. Eventuell zur Modellierung früher Phasen exponentiellen Lernens oder bei Netzwerkeffekten, wo mehr Einsatz (z. B. in Verbreitung) exponentielle Ergebnisse (z. B. Nutzerzahlen) bringt.\n\n\n\n1.4.3 4. Logarithmischer Zusammenhang\n\nBeschreibung: Die Leistung steigt mit dem Aufwand, aber der Zuwachs wird immer geringer (abnehmender Grenzertrag). Die ersten Aufwandseinheiten bringen den größten Leistungszuwachs.\nMathematische Formel: \\[ P = a + b \\cdot \\log(E) \\quad (\\text{wobei } E &gt; 0) \\]\n\n\\(a\\): Verschiebungsparameter\n\\(b\\): Skaliert den logarithmischen Effekt\n\nTypische Einsatzbereiche: Lernkurven (Anfänger lernen schnell, Experten brauchen viel Aufwand für kleine Verbesserungen), Skill-Akquisition, Ressourcennutzung (erste Düngergaben haben größten Effekt), generell Situationen mit Sättigungseffekten. Dies ist ein häufig in der Literatur diskutierter nicht-linearer Zusammenhang.\n\n\n\n1.4.4 5. Sigmoidaler / Logistischer Zusammenhang\n\nBeschreibung: S-förmige Kurve. Anfänglich langsamer Leistungszuwachs bei steigendem Aufwand (Initialaufwand, Einarbeitung), dann eine Phase schnellen Wachstums, gefolgt von einer Abflachung hin zu einem Leistungsplateau (Sättigung, maximale Kapazität).\nMathematische Formel (Logistische Funktion): \\[ P = \\frac{L}{1 + \\exp(-k(E - E_0))} \\]\n\n\\(L\\): Maximales Leistungsniveau (Plateau)\n\\(k\\): Steilheit der Kurve\n\\(E_0\\): Aufwandswert beim Wendepunkt (halbe maximale Leistung)\n\nTypische Einsatzbereiche: Sehr häufig zur Modellierung von Lernprozessen über die Zeit, Skill-Akquisition bei komplexen Aufgaben, Technologie-Adoption, biologische Wachstumsprozesse. Gilt als sehr plausibles Modell für viele Effort-Performance-Szenarien, da es sowohl Anlaufschwierigkeiten als auch Sättigung abbildet.\n\n\n\nWarning: Paket 'plotly' wurde unter R Version 4.3.3 erstellt\n\n\nWarning: Paket 'tidyr' wurde unter R Version 4.3.3 erstellt\n\n\n\n\n\nFigure 1.1: Interaktive Visualisierung verschiedener möglicher Zusammenhänge zwischen Effort und Performance"
  },
  {
    "objectID": "1_Literaturrecherche.html",
    "href": "1_Literaturrecherche.html",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "",
    "text": "2 Verwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n«Konvertiere sämtliche Referenzen in diesem Text in die passenden APA7 Zitate und ein passendes Literaturverzeichnis:» Das entstandene Dokument wurde erneut abgespeichert. (Deep_Research_ChatGPT_Output_2). :::"
  },
  {
    "objectID": "1_Literaturrecherche.html#polynomieller-zusammenhang",
    "href": "1_Literaturrecherche.html#polynomieller-zusammenhang",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Polynomieller Zusammenhang",
    "text": "1.4 Polynomieller Zusammenhang\nKurzbeschreibung\n- Die Leistung steigt nicht nur linear, sondern kann Wendepunkte oder Kurvenverläufe höherer Ordnung aufweisen.\nMathematische Standardformel (quadratisch als Beispiel)\n[ = _0 + _1 + _2 ^2 ]\nForschungsfrage-Hinweis\n- Wird häufig geprüft, wenn man nicht-lineare Effekte wie Sättigung oder abnehmende Grenzerträge erwartet.\nBeispiel-Visualisierung (ggplot2)\n\nset.seed(123)\nEffort_poly &lt;- seq(1, 10, by = 0.2)\nPerformance_poly &lt;- 2 + 1.5*Effort_poly - 0.1*Effort_poly^2 + rnorm(length(Effort_poly), 0, 1)\ndf_poly &lt;- data.frame(Effort = Effort_poly, Performance = Performance_poly)\n\nggplot(df_poly, aes(x = Effort, y = Performance)) +\n  geom_point(color = \"#D55E00\", alpha = 0.6) +\n  geom_smooth(formula = y ~ poly(x, 2), method = \"lm\", color = \"#0072B2\", se = FALSE) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Polynomielle (quadratische) Beziehung\",\n       x = \"Effort\",\n       y = \"Performance\")"
  },
  {
    "objectID": "1_Literaturrecherche.html#exponentielle-beziehung",
    "href": "1_Literaturrecherche.html#exponentielle-beziehung",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Exponentielle Beziehung",
    "text": "1.5 Exponentielle Beziehung\nKurzbeschreibung\n- Kleine Änderungen im „Effort“ können zu stark wachsenden oder stark abnehmenden Veränderungen der „Performance“ führen.\nMathematische Standardformel\n[ = _0 e^{(_1 )} ]\nForschungsfrage-Hinweis\n- Wenn angenommen wird, dass ein höherer „Effort“ sprunghaft höhere „Performance“ erzeugt (oder umgekehrt stark fällt).\nBeispiel-Visualisierung (ggplot2)\n\nset.seed(123)\nEffort_expo &lt;- seq(1, 5, by = 0.1)\nPerformance_expo &lt;- 2 * exp(0.8*Effort_expo) + rnorm(length(Effort_expo), 0, 5)\ndf_expo &lt;- data.frame(Effort = Effort_expo, Performance = Performance_expo)\n\nlibrary(minpack.lm)  # ggf. für robustes nls\n\nggplot(df_expo, aes(x = Effort, y = Performance)) +\n  geom_point(color = \"#D55E00\", alpha = 0.6) +\n  stat_smooth(method = \"nls\", \n              formula = y ~ a*exp(b*x),\n              method.args = list(start = list(a=1, b=1)),\n              se = FALSE, color=\"#0072B2\") +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Exponentieller Zusammenhang\",\n       x = \"Effort\",\n       y = \"Performance\")"
  },
  {
    "objectID": "1_Literaturrecherche.html#logarithmischer-zusammenhang",
    "href": "1_Literaturrecherche.html#logarithmischer-zusammenhang",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.6 Logarithmischer Zusammenhang",
    "text": "1.6 Logarithmischer Zusammenhang\nKurzbeschreibung\n- Zu Beginn führt ein kleiner Anstieg bei „Effort“ zu relativ hohem Zuwachs in „Performance“, danach flacht die Kurve ab.\nMathematische Standardformel\n[ = _0 + _1 () ]\nForschungsfrage-Hinweis\n- Erklärt eine schnell ansteigende Performance, die sich auf längere Sicht immer weiter verlangsamt.\nBeispiel-Visualisierung (ggplot2)\n\nset.seed(123)\nEffort_log &lt;- seq(1, 50, by = 1)\nPerformance_log &lt;- 10 + 20*log(Effort_log) + rnorm(length(Effort_log), 0, 5)\ndf_log &lt;- data.frame(Effort = Effort_log, Performance = Performance_log)\n\nggplot(df_log, aes(x = Effort, y = Performance)) +\n  geom_point(color = \"#D55E00\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", formula = y ~ log(x), color = \"#0072B2\", se = FALSE) +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Logarithmischer Zusammenhang\",\n       x = \"Effort\",\n       y = \"Performance\")"
  },
  {
    "objectID": "1_Literaturrecherche.html#sigmoidlogistisch",
    "href": "1_Literaturrecherche.html#sigmoidlogistisch",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.7 Sigmoid/Logistisch",
    "text": "1.7 Sigmoid/Logistisch\nKurzbeschreibung\n- Zunächst geringes Wachstum, gefolgt von einer Phase schnellen Anstiegs, bevor eine Sättigung erreicht wird.\nMathematische Standardformel (Logistische Funktion)\n[ = ]\nForschungsfrage-Hinweis\n- Häufig angenommen, wenn Performancesteigerung zunächst langsam, dann beschleunigt verläuft und sich schließlich stabilisiert.\nBeispiel-Visualisierung (ggplot2)\n\nset.seed(123)\nEffort_sig &lt;- seq(0, 10, by = 0.1)\n\nlogistic &lt;- function(x, b0, b1) {\n  1 / (1 + exp(-(b0 + b1*x)))\n}\n\nPerformance_sig &lt;- logistic(Effort_sig, b0 = -5, b1 = 1.2) + rnorm(length(Effort_sig), 0, 0.02)\ndf_sig &lt;- data.frame(Effort = Effort_sig, Performance = Performance_sig)\n\nggplot(df_sig, aes(x = Effort, y = Performance)) +\n  geom_point(color = \"#D55E00\", alpha = 0.6) +\n  stat_smooth(method = \"nls\", \n              formula = y ~ 1/(1+exp(-(b0+b1*x))),\n              method.args = list(start = list(b0=-5, b1=1)),\n              se = FALSE, color=\"#0072B2\") +\n  theme_minimal(base_size = 14) +\n  labs(title = \"Sigmoider/Logistischer Zusammenhang\",\n       x = \"Effort\",\n       y = \"Performance\")"
  },
  {
    "objectID": "1_Literaturrecherche.html#eigene-suche-nach-forschungsliteratur-zum",
    "href": "1_Literaturrecherche.html#eigene-suche-nach-forschungsliteratur-zum",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Eigene Suche nach Forschungsliteratur zum",
    "text": "1.4 Eigene Suche nach Forschungsliteratur zum\nDie Literaturssuche erfolgte zunächst unsystematisch und explorativ. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung zu revolutionieren (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es vielversprechende Open Source Ansätze zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025).\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI Recherche, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchanfrage und einen Überblick über die wichtigsten Datenbanken. Berücksichtige ausschliesslich Top Journals bei der Suche.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier ist eine Strategie, um in frei verfügbaren Forschungsdatenbanken nach Workflows für AI-gestützte Recherche zu suchen, unter Berücksichtigung von Top-Journalen. 1. Kernkonzepte und Suchbegriffe (Deutsch & Englisch): AI Recherche / AI-gestützte Recherche: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing (NLP), Large Language Models (LLM), Generative AI, OpenAI, AI-assisted research, AI-powered research, computational research methods. Workflows: Workflow, methodology, process, pipeline, framework, standard operating procedure (SOP), systematic approach. Kontext (Forschungsarten): Literature review, systematic review, evidence synthesis, knowledge discovery, information retrieval, research automation, data analysis. “Deep Research”: Dieser Begriff ist nicht standardisiert. Er könnte sich auf “Deep Learning” beziehen oder einfach auf “tiefgehende/umfassende Recherche”. Wir integrieren beides. 2. Optimierte Suchanfrage (Basis für die meisten Datenbanken): Diese Anfrage kombiniert die Kernkonzepte mit Booleschen Operatoren (AND, OR) und Phrasensuche (” “). Sie ist bewusst breit gehalten, um relevante Treffer nicht auszuschließen, kann aber je nach Datenbank angepasst werden. (”Artificial Intelligence” OR “AI” OR “Machine Learning” OR “Deep Learning” OR “Natural Language Processing” OR “NLP” OR “Large Language Model” OR “LLM” OR “OpenAI” OR “Generative AI”) AND (workflow* OR methodology OR process OR pipeline OR framework OR “systematic approach”) AND (research OR “literature review” OR “systematic review” OR “knowledge discovery” OR “information retrieval” OR “evidence synthesis”) Use code with caution. Erläuterung: (A OR B OR C): Findet Dokumente, die mindestens einen der Begriffe in Klammern enthalten. AND: Verknüpft die drei Hauptkonzeptgruppen – es müssen Begriffe aus jeder Gruppe vorkommen. “Phrase”: Sucht nach der exakten Wortkombination. workflow: Sucht nach “workflow” und “workflows” (Platzhalter , falls von der Datenbank unterstützt). Variationen/Verfeinerungen: Fokus auf Assistenz: Ersetzen Sie die erste Klammer durch oder ergänzen Sie sie mit (“AI-assisted” OR “AI-powered” OR “AI-driven”). Enger gefasst (falls zu viele Treffer): Entfernen Sie allgemeinere Begriffe wie “AI” oder “research” und konzentrieren Sie sich auf spezifischere wie “Large Language Model” oder “systematic review”. 3. Wichtige frei verfügbare Forschungsdatenbanken: Hier sind die wichtigsten Datenbanken, die breit gefächert sind und/oder für Informatik/AI relevant sind. Die Einschränkung auf “Top Journals” ist bei frei verfügbaren Datenbanken oft nur indirekt oder manuell möglich. Google Scholar: Stärken: Sehr breite Abdeckung (Artikel, Preprints, Thesen, Bücher), Zitationsverfolgung, oft Links zu frei verfügbaren PDFs (auch von Top-Journalen, wenn Open Access oder über Repositorien). Schwächen: Weniger präzise Suchfilter als spezialisierte Datenbanken. Kein direkter Filter für “Top Journals”. Man muss die Zeitschrift des gefundenen Artikels selbst bewerten. Anwendung der Suche: Die obige Suchanfrage kann gut verwendet werden. Sortierung nach Relevanz oder Zitationen kann helfen, wichtige Arbeiten zu finden. PubMed Central (PMC): Stärken: Fokus auf Biomedizin und Lebenswissenschaften, aber auch Berührungspunkte mit Informatik/AI in der Bioinformatik etc. Enthält einen großen Teil frei zugänglicher Volltexte. Schwächen: Thematisch eingeschränkter als Google Scholar. Kein direkter Filter für “Top Journal”-Status, aber man kann nach spezifischen (bekannten Top-)Journalen filtern. Anwendung der Suche: Die Suchanfrage kann angepasst werden (z.B. Fokus auf medizinische Anwendungen von AI-Recherche-Workflows). arXiv.org: Stärken: Der Preprint-Server für Physik, Mathematik, Informatik (inkl. AI, ML, CL), Statistik etc. Enthält oft die aktuellsten Forschungsarbeiten, noch vor der Veröffentlichung in Journals. Viele Arbeiten landen später in Top-Journalen oder Konferenzen. Schwächen: Enthält Preprints, d.h. noch nicht final begutachtete Artikel. Kein Journal-Kontext per se. Anwendung der Suche: Die Suchanfrage ist hier sehr gut anwendbar. Fokus auf die relevanten Kategorien (cs.AI, cs.CL, cs.IR etc.). Semantic Scholar: Stärken: AI-gestützte Suchmaschine mit Fokus auf Informatik und Biomedizin. Versucht, Kontext, Einfluss und Verbindungen zwischen Papern darzustellen. Identifiziert oft frei verfügbare PDFs. Kann nach “Top Influential” sortieren. Schwächen: Kein expliziter “Top Journal”-Filter, aber die Relevanz-/Einfluss-Sortierung kann helfen. Anwendung der Suche: Die Suchanfrage kann gut verwendet werden. Die zusätzlichen Analyse-Features sind nützlich. CORE (core.ac.uk): Stärken: Aggregiert Open-Access-Inhalte aus institutionellen Repositorien und Journalen weltweit. Sehr große Datenbasis frei verfügbarer Artikel. Schwächen: Qualität der Metadaten kann variieren. Kein direkter Filter für “Top Journals”. Man muss die Quelle selbst prüfen. Anwendung der Suche: Die Suchanfrage ist hier gut anwendbar. Dimensions (App - Free Version): Stärken: Sehr breite Abdeckung (Publikationen, Grants, Patente, Clinical Trials). Gute analytische Werkzeuge und Zitationsdaten. Verlinkt oft zu freien Versionen. Schwächen: Die kostenlose Version hat Einschränkungen bei Export und Analyse. Kein direkter Filter für “Top Journals”, aber man sieht die publizierende Zeitschrift. Anwendung der Suche: Die Suchanfrage kann genutzt werden. 4. Umgang mit der Einschränkung “Ausschließlich Top Journals”: Das ist die größte Herausforderung bei frei verfügbaren Datenbanken. Direkte Filter gibt es meist nicht. Vorgehensweise: Breit suchen: Verwenden Sie die obige Suchanfrage in den genannten Datenbanken (insbesondere Google Scholar, arXiv, Semantic Scholar). Ergebnisse sichten: Identifizieren Sie vielversprechende Treffer basierend auf Titel und Abstract. Journal prüfen: Notieren Sie sich bei relevanten Treffern den Namen der Zeitschrift (oder Konferenz, bei Informatik oft genauso wichtig!). Journal-Ranking verifizieren: Überprüfen Sie den Ruf/das Ranking der Zeitschrift. Dazu können Sie (falls Zugang besteht z.B. über eine Bibliothek) auf Journal Citation Reports (JCR) oder Scimago Journal Rank (SJR, frei verfügbar) zurückgreifen oder Listen von Top-Journalen im Bereich Informatik/AI konsultieren (z.B. von Universitäten oder Fachgesellschaften wie ACM/IEEE). Bei Konferenzen hilft das CORE Ranking. Fokus: Konzentrieren Sie sich auf die Artikel, die in den als “Top” identifizierten Journalen/Konferenzen erschienen sind. Zusammenfassend: Nutzen Sie die optimierte Suchanfrage als Basis. Durchsuchen Sie Google Scholar, arXiv und Semantic Scholar als primäre Quellen. Ergänzen Sie ggf. mit PMC, CORE, Dimensions. Seien Sie sich bewusst, dass die Filterung nach “Top Journals” ein manueller Nachbearbeitungsschritt ist, bei dem Sie die Publikationsorte der gefundenen relevanten Artikel selbst bewerten müssen. Viel Erfolg bei Ihrer Recherche!"
  },
  {
    "objectID": "1_Literaturrecherche.html#eigene-suche-nach-forschungsliteratur-zum-thema-ki-unterstütze-suche-nach-forschungsliteratur",
    "href": "1_Literaturrecherche.html#eigene-suche-nach-forschungsliteratur-zum-thema-ki-unterstütze-suche-nach-forschungsliteratur",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Eigene Suche nach Forschungsliteratur zum Thema KI unterstütze Suche nach Forschungsliteratur",
    "text": "1.4 Eigene Suche nach Forschungsliteratur zum Thema KI unterstütze Suche nach Forschungsliteratur\nDie Literatursuche erfolgte zunächst unsystematisch und explorativ. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung zu revolutionieren (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es vielversprechende Open Source Ansätze zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025).\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI unterstützte Recherche aber auch konkreten Tools wie “ChatGPT”, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchparameter für Google Scholar und ähnliche Suchmaschinen als praktische Tabelle (verschiedene Alternativssuchmöglichkeiten) und anschliessend einen Überblick über die wichtigsten Datenbanken, die ich mir anschauen sollte.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier ist eine Strategie, um in frei verfügbaren Forschungsdatenbanken nach Workflows für AI-gestützte Recherche zu suchen, unter Berücksichtigung von Top-Journalen. 1. Kernkonzepte und Suchbegriffe (Deutsch & Englisch): AI Recherche / AI-gestützte Recherche: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing (NLP), Large Language Models (LLM), Generative AI, OpenAI, AI-assisted research, AI-powered research, computational research methods. Workflows: Workflow, methodology, process, pipeline, framework, standard operating procedure (SOP), systematic approach. Kontext (Forschungsarten): Literature review, systematic review, evidence synthesis, knowledge discovery, information retrieval, research automation, data analysis. “Deep Research”: Dieser Begriff ist nicht standardisiert. Er könnte sich auf “Deep Learning” beziehen oder einfach auf “tiefgehende/umfassende Recherche”. Wir integrieren beides. 2. Optimierte Suchanfrage (Basis für die meisten Datenbanken): Diese Anfrage kombiniert die Kernkonzepte mit Booleschen Operatoren (AND, OR) und Phrasensuche (” “). Sie ist bewusst breit gehalten, um relevante Treffer nicht auszuschließen, kann aber je nach Datenbank angepasst werden. (”Artificial Intelligence” OR “AI” OR “Machine Learning” OR “Deep Learning” OR “Natural Language Processing” OR “NLP” OR “Large Language Model” OR “LLM” OR “OpenAI” OR “Generative AI”) AND (workflow* OR methodology OR process OR pipeline OR framework OR “systematic approach”) AND (research OR “literature review” OR “systematic review” OR “knowledge discovery” OR “information retrieval” OR “evidence synthesis”) Use code with caution. Erläuterung: (A OR B OR C): Findet Dokumente, die mindestens einen der Begriffe in Klammern enthalten. AND: Verknüpft die drei Hauptkonzeptgruppen – es müssen Begriffe aus jeder Gruppe vorkommen. “Phrase”: Sucht nach der exakten Wortkombination. workflow: Sucht nach “workflow” und “workflows” (Platzhalter , falls von der Datenbank unterstützt). Variationen/Verfeinerungen: Fokus auf Assistenz: Ersetzen Sie die erste Klammer durch oder ergänzen Sie sie mit (“AI-assisted” OR “AI-powered” OR “AI-driven”). Enger gefasst (falls zu viele Treffer): Entfernen Sie allgemeinere Begriffe wie “AI” oder “research” und konzentrieren Sie sich auf spezifischere wie “Large Language Model” oder “systematic review”. 3. Wichtige frei verfügbare Forschungsdatenbanken: Hier sind die wichtigsten Datenbanken, die breit gefächert sind und/oder für Informatik/AI relevant sind. Die Einschränkung auf “Top Journals” ist bei frei verfügbaren Datenbanken oft nur indirekt oder manuell möglich. Google Scholar: Stärken: Sehr breite Abdeckung (Artikel, Preprints, Thesen, Bücher), Zitationsverfolgung, oft Links zu frei verfügbaren PDFs (auch von Top-Journalen, wenn Open Access oder über Repositorien). Schwächen: Weniger präzise Suchfilter als spezialisierte Datenbanken. Kein direkter Filter für “Top Journals”. Man muss die Zeitschrift des gefundenen Artikels selbst bewerten. Anwendung der Suche: Die obige Suchanfrage kann gut verwendet werden. Sortierung nach Relevanz oder Zitationen kann helfen, wichtige Arbeiten zu finden. PubMed Central (PMC): Stärken: Fokus auf Biomedizin und Lebenswissenschaften, aber auch Berührungspunkte mit Informatik/AI in der Bioinformatik etc. Enthält einen großen Teil frei zugänglicher Volltexte. Schwächen: Thematisch eingeschränkter als Google Scholar. Kein direkter Filter für “Top Journal”-Status, aber man kann nach spezifischen (bekannten Top-)Journalen filtern. Anwendung der Suche: Die Suchanfrage kann angepasst werden (z.B. Fokus auf medizinische Anwendungen von AI-Recherche-Workflows). arXiv.org: Stärken: Der Preprint-Server für Physik, Mathematik, Informatik (inkl. AI, ML, CL), Statistik etc. Enthält oft die aktuellsten Forschungsarbeiten, noch vor der Veröffentlichung in Journals. Viele Arbeiten landen später in Top-Journalen oder Konferenzen. Schwächen: Enthält Preprints, d.h. noch nicht final begutachtete Artikel. Kein Journal-Kontext per se. Anwendung der Suche: Die Suchanfrage ist hier sehr gut anwendbar. Fokus auf die relevanten Kategorien (cs.AI, cs.CL, cs.IR etc.). Semantic Scholar: Stärken: AI-gestützte Suchmaschine mit Fokus auf Informatik und Biomedizin. Versucht, Kontext, Einfluss und Verbindungen zwischen Papern darzustellen. Identifiziert oft frei verfügbare PDFs. Kann nach “Top Influential” sortieren. Schwächen: Kein expliziter “Top Journal”-Filter, aber die Relevanz-/Einfluss-Sortierung kann helfen. Anwendung der Suche: Die Suchanfrage kann gut verwendet werden. Die zusätzlichen Analyse-Features sind nützlich. CORE (core.ac.uk): Stärken: Aggregiert Open-Access-Inhalte aus institutionellen Repositorien und Journalen weltweit. Sehr große Datenbasis frei verfügbarer Artikel. Schwächen: Qualität der Metadaten kann variieren. Kein direkter Filter für “Top Journals”. Man muss die Quelle selbst prüfen. Anwendung der Suche: Die Suchanfrage ist hier gut anwendbar. Dimensions (App - Free Version): Stärken: Sehr breite Abdeckung (Publikationen, Grants, Patente, Clinical Trials). Gute analytische Werkzeuge und Zitationsdaten. Verlinkt oft zu freien Versionen. Schwächen: Die kostenlose Version hat Einschränkungen bei Export und Analyse. Kein direkter Filter für “Top Journals”, aber man sieht die publizierende Zeitschrift. Anwendung der Suche: Die Suchanfrage kann genutzt werden. 4. Umgang mit der Einschränkung “Ausschließlich Top Journals”: Das ist die größte Herausforderung bei frei verfügbaren Datenbanken. Direkte Filter gibt es meist nicht. Vorgehensweise: Breit suchen: Verwenden Sie die obige Suchanfrage in den genannten Datenbanken (insbesondere Google Scholar, arXiv, Semantic Scholar). Ergebnisse sichten: Identifizieren Sie vielversprechende Treffer basierend auf Titel und Abstract. Journal prüfen: Notieren Sie sich bei relevanten Treffern den Namen der Zeitschrift (oder Konferenz, bei Informatik oft genauso wichtig!). Journal-Ranking verifizieren: Überprüfen Sie den Ruf/das Ranking der Zeitschrift. Dazu können Sie (falls Zugang besteht z.B. über eine Bibliothek) auf Journal Citation Reports (JCR) oder Scimago Journal Rank (SJR, frei verfügbar) zurückgreifen oder Listen von Top-Journalen im Bereich Informatik/AI konsultieren (z.B. von Universitäten oder Fachgesellschaften wie ACM/IEEE). Bei Konferenzen hilft das CORE Ranking. Fokus: Konzentrieren Sie sich auf die Artikel, die in den als “Top” identifizierten Journalen/Konferenzen erschienen sind. Zusammenfassend: Nutzen Sie die optimierte Suchanfrage als Basis. Durchsuchen Sie Google Scholar, arXiv und Semantic Scholar als primäre Quellen. Ergänzen Sie ggf. mit PMC, CORE, Dimensions. Seien Sie sich bewusst, dass die Filterung nach “Top Journals” ein manueller Nachbearbeitungsschritt ist, bei dem Sie die Publikationsorte der gefundenen relevanten Artikel selbst bewerten müssen. Viel Erfolg bei Ihrer Recherche!"
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-deep-research-tools",
    "href": "1_Literaturrecherche.html#recherche-mit-deep-research-tools",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Recherche mit Deep Research Tools",
    "text": "1.5 Recherche mit Deep Research Tools\n\n1.5.1 1. Prompt für eine Anfrage zum Thema Workflow für die Recherche mit Deep Research mit AI optimieren\nZunächst wurde der Prompt für eine AI Literaturrecherche mit Google AI Studio https://aistudio.google.com/ und dem Modell “Gemini 2.5 Pro Preview 03-25” (Stand 13.04.2025) optimiert:\n\n\n\n\n\n\nVerwendeter Prompt:\n\n\n\n\n\nOptimiere meinen Prompt zum Thema KI unterstützte Literaturrecherche in der Forschung. Wie kann ich das im Jahr 2025 optimalerweise machen? Es geht darum einen perfekten Workflow für den Einsatz sämtlicher relevanten Tools (LLMs aber auch Einsatz von Python etc.) zu bekommen, inkl. möglicher Gefahren und Chancen. Der ganze Workflow muss extrem ausführlich beschrieben sein und darf niemals hypothetische Tools oder Funktionen beinhalten, sondern muss ausschliesslich auf bekannte Funktionalitäten aufsetzen. Ich brauche einen vollständigen Prompt.\n\n\n\n\n\n\n\n\n\nAI Output\n\n\n\n\n\nOkay, hier ist ein optimierter Prompt, der darauf abzielt, einen detaillierten, praxisnahen und auf bekannten Technologien basierenden Workflow für die KI-gestützte Literaturrecherche im Jahr 2025 zu generieren. Dieser Prompt ist so formuliert, dass er einer leistungsstarken KI (wie GPT-4 oder Nachfolgemodellen) gegeben werden kann, um den gewünschten Workflow zu erstellen.\n\nPrompt:\nRolle: Du bist ein Experte für Forschungsmethodik, wissenschaftliches Arbeiten und den Einsatz von künstlicher Intelligenz in der Wissenschaft, mit einem Fokus auf den Stand der Technik Anfang 2025.\nAufgabe: Erstelle einen extrem ausführlichen, schrittweisen Workflow für die Durchführung einer umfassenden Literaturrecherche in einem beliebigen Forschungsfeld unter maximaler Nutzung von KI-Tools und -Technologien, wie sie bis Anfang 2025 realistischerweise etabliert und zugänglich sind. Der Workflow muss praxisorientiert sein und sich ausschließlich auf bekannte und verfügbare Funktionalitäten stützen. Hypothetische oder zukünftige, noch nicht entwickelte Tools oder Funktionen dürfen NICHT inkludiert werden.\nZielgruppe des Workflows: Wissenschaftler und Forscher (Doktoranden, Postdocs, etablierte Forscher).\nAnforderungen an den Workflow:\n\nDetaillierungsgrad: Jeder Schritt muss sehr detailliert beschrieben werden. Was genau ist zu tun? Welche spezifischen (Typen von) Tools werden eingesetzt? Wie interagieren die Tools? Wo ist menschliches Eingreifen und kritische Bewertung unerlässlich?\nPhasen: Gliedere den Workflow logisch in die typischen Phasen einer Literaturrecherche, z. B.:\n\nPhase 1: Planung & Definition (Forschungsfrage schärfen, Suchstrategie konzipieren)\nPhase 2: Suche & Identifikation (Papers finden)\nPhase 3: Screening & Auswahl (Relevanzprüfung)\nPhase 4: Datenextraktion & Analyse (Informationen aus Papers ziehen)\nPhase 5: Synthese & Berichterstattung (Ergebnisse zusammenfassen, Lücken identifizieren)\nPhase 6: Management & Aktualisierung (Referenzen verwalten, Recherche aktuell halten)\n\nTool-Integration: Beschreibe bei jedem relevanten Schritt konkret, wie folgende Tool-Kategorien (basierend auf Stand Anfang 2025) eingesetzt werden können:\n\nLarge Language Models (LLMs): z.B. GPT-4/Nachfolger, Claude-Modelle, Gemini/Bard für Aufgaben wie Brainstorming, Keyword-Generierung, Textzusammenfassung, Umformulierung, erste Syntheseentwürfe, Query-Optimierung. Spezifiziere die genaue Anwendung und die notwendige menschliche Verifikation.\nSpezialisierte KI-Such- und Analyseplattformen: z.B. Elicit, Semantic Scholar, Scite, ResearchRabbit, Connected Papers, Litmaps. Beschreibe deren spezifische Stärken (semantische Suche, Zitationsanalyse, Visualisierung von Forschungslandschaften, Frage-Antwort-Systeme basierend auf Papers).\nKI-gestützte Screening-Tools: z.B. Funktionen in systematischer Review-Software (Rayyan, Covidence) oder dedizierte Tools, die beim Priorisieren/Screenen von Abstracts helfen (basierend auf trainierten Algorithmen).\nReferenzmanagement-Software: z.B. Zotero, Mendeley, EndNote. Beschreibe auch mögliche KI-Integrationen (sofern bis Anfang 2025 Standard), z.B. für Duplikaterkennung oder Empfehlungen.\n(Optional aber empfohlen) Python-Skripte: Beschreibe einfache, realistische Anwendungsfälle für Forscher mit grundlegenden Python-Kenntnissen, z.B. zur Automatisierung von API-Abfragen (PubMed API, Crossref API), zur Deduplizierung von Suchergebnissen, zur einfachen Textanalyse (z.B. Frequenzanalysen von Keywords) oder zur Datenaufbereitung für Visualisierungen. Nutze bekannte Bibliotheken (z.B. requests, pandas, nltk, spacy, bibtexparser).\nTraditionelle Datenbanken: Betone, dass PubMed, Scopus, Web of Science etc. weiterhin essenziell sind und wie KI-Tools die Suche ergänzen, aber nicht ersetzen.\n\nChancen und Gefahren: Gehe bei jedem Schritt oder zumindest bei jeder Phase explizit und detailliert auf die spezifischen Chancen (z.B. Effizienzsteigerung, breitere Abdeckung, neue Einsichten) und Gefahren/Risiken (z.B. Halluzinationen von LLMs, Bias in Algorithmen, Verlust kritischer Fähigkeiten, Reproduzierbarkeitsprobleme, Datenschutz, “Filterblasen”-Effekte) des jeweiligen KI-Einsatzes ein. Gib konkrete Mitigationsstrategien an, wie Forscher diesen Gefahren begegnen können (z.B. Verifikationsprotokolle, Nutzung mehrerer Tools, kritische manuelle Prüfung).\nPraxisnähe und Reproduzierbarkeit: Der Workflow muss praktisch umsetzbar sein. Gib Hinweise zur Dokumentation des Vorgehens (welche Tools, Versionen, Prompts wurden verwendet?), um die Nachvollziehbarkeit zu gewährleisten.\nKeine Hypothetik: Stelle sicher, dass alle beschriebenen Tools und Funktionalitäten auf dem real existierenden Stand von Anfang 2025 basieren. Vermeide Aussagen wie “In Zukunft wird es möglich sein…” oder “Ein hypothetisches Tool könnte…”. Beziehe dich auf das, was bekannt ist.\nOutput-Format: Strukturiere die Antwort klar und übersichtlich, idealerweise mit nummerierten Schritten innerhalb der Phasen und klaren Unterabschnitten für Tools, Chancen, Gefahren und Mitigation pro Schritt/Phase.\n\nZusammenfassend: Erzeuge den bestmöglichen, detaillierten und realistischen Workflow für KI-gestützte Literaturrecherche (Stand Anfang 2025), der Forschern als praktische Anleitung dient und dabei Chancen und Risiken klar benennt und adressiert. Der Fokus liegt auf der Integration und dem Zusammenspiel bekannter Tools und Techniken.\n\nWarum dieser Prompt optimiert ist:\n\nKlare Rolle und Kontext: Definiert die Expertise der KI und den Zeitrahmen (Anfang 2025).\nSpezifische Anforderungen: Listet detailliert auf, was der Workflow enthalten muss (Phasen, Tool-Typen, Chancen/Gefahren, Detailgrad).\nFokus auf Realismus: Die Einschränkung “ausschließlich bekannte Funktionalitäten” und “keine Hypothetik” ist explizit und mehrfach genannt, um unrealistische Ergebnisse zu vermeiden.\nKonkrete Tool-Beispiele: Nennt Beispiele für jede Tool-Kategorie, um der KI eine klare Vorstellung zu geben, ohne sich auf nur ein Tool festzulegen.\nIntegration von Chancen/Gefahren: Fordert die Einbettung dieser Aspekte direkt in den Workflow, nicht nur als separaten Anhang. Verlangt auch Mitigationsstrategien.\nBetonung von Praxisnähe und Reproduzierbarkeit: Wichtige Aspekte für wissenschaftliches Arbeiten.\nStrukturvorgabe: Hilft der KI, einen gut organisierten Output zu liefern.\nZielgruppenorientierung: Stellt sicher, dass der Workflow für Forscher relevant ist.\n\nDieser Prompt sollte eine KI dazu bringen, einen sehr umfassenden und nützlichen Workflow zu generieren, der deinen Anforderungen entspricht."
  },
  {
    "objectID": "1_Literaturrecherche.html#auswahl-der-methodologie-für-die-suche",
    "href": "1_Literaturrecherche.html#auswahl-der-methodologie-für-die-suche",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.3 Auswahl der Methodologie für die Suche",
    "text": "1.3 Auswahl der Methodologie für die Suche\n\n1.3.1 Menschliche Suche nach Forschungsliteratur zum Thema “KI unterstützte Suche nach Forschungsliteratur”\nDie Literatursuche erfolgte zunächst unsystematisch und explorativ in einem Scoping Prozess. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. In diesem Scoping Prozess scheinen auch die besonderen Stärken der KI zu liegen (Gusenbauer & Gauster, 2025). Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung radikal zu verändern (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es auch vielversprechende Open Source Ansätze in diesem Bereich zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025). Die erste Scopingsuche war wenig erfolgreich, deshalb wurde in einem nächsten Schritt des Prozesses versucht die Suchbegriffe etwas zu verbessern, dazu wurde folgendes Prompting mit Google AI Studio verwendet um die Suche zu optimieren .\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI unterstützte Recherche aber auch konkreten Tools wie “ChatGPT”, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchparameter für Google Scholar und ähnliche Suchmaschinen als praktische Tabelle (verschiedene Alternativssuchmöglichkeiten) und anschliessend einen Überblick über die wichtigsten Datenbanken, die ich mir anschauen sollte.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier sind optimierte Suchparameter und eine Übersicht über relevante Forschungsdatenbanken für Ihre Suche nach Workflows und Tools im Bereich KI-unterstützte Recherche.\n1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\n\n\n\n\n\n\n\n\nFokus / Ziel\nSuchbegriffe (Beispiele für Google Scholar & Co.)\nHinweise / Strategie\n\n\nBreit: KI & Recherche allgemein\n“artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review”\nStartpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten.\n\n\nFokus: KI-Unterstützung im Workflow\n“AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review”\nKonzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews.\n\n\nFokus: Generative KI / LLMs in Recherche\n“Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery”\nZielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen.\n\n\nSpezifisch: ChatGPT in Recherche\n“ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”)\nSucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen.\n\n\nSpezifisch: OpenAI (als Technologiegeber)\n“OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”)\nVorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research”\n\n\nSpezifisch: Andere Tools (Beispiel)\n“Deep Research” AND “AI” AND (“research tool” OR “literature review”)\nErsetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung.\n\n\nFokus: KI-Tools für Recherche\n“AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform”\nSucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung.\n\n\nKombination: Workflow & Spezifisches Tool\n(“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”)\nKombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools.\n\n\nAlternative Formulierungen\n“intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search”\nFängt alternative Bezeichnungen und Konzepte auf.\n\n\n\nWichtige Tipps zur Suche:\n\n**Anführungszeichen (” “):** Verwenden Sie sie für exakte Phrasen (z.B.”literature review”).\nOR Operator: Muss oft großgeschrieben werden. Dient zur Suche nach Alternativen (z.B. AI OR “artificial intelligence”). Klammern () können zur Gruppierung genutzt werden: (AI OR “artificial intelligence”) AND (“literature review” OR “research workflow”).\nAND Operator: Verbindet verschiedene Konzepte. Oft implizit (Leerzeichen genügt).\nPlatzhalter (*): Manche Datenbanken erlauben Wildcards (z.B. research* findet research, researcher, researching). Mit Vorsicht verwenden, kann unspezifisch werden.\nFilter nutzen: Fast alle Datenbanken erlauben Filter nach Publikationsdatum (sehr wichtig bei diesem schnelllebigen Thema!), Dokumenttyp (Journal Article, Conference Paper, Review etc.), Fachgebiet etc. Nutzen Sie insbesondere den Datumsfilter (z.B. letzte 1-3 Jahre).\nVariieren: Keine einzelne Suche ist perfekt. Probieren Sie verschiedene Kombinationen aus.\n\n2. Wichtige frei verfügbare Forschungsdatenbanken\nHier ist eine Liste der wichtigsten Datenbanken, wobei der “freie Zugang” oft bedeutet, dass die Suche und Abstracts frei sind, der Volltext aber hinter einer Paywall liegen kann (oft über Universitäts-/Institutionsbibliotheken zugänglich).\n\n\n\n\n\n\n\n\n\nDatenbank\nFokus / Beschreibung\nZugang\nRelevanz für Ihr Thema\n\n\nGoogle Scholar\nSehr breite Abdeckung über alle Disziplinen, inklusive Preprints, Konferenzbeiträge, Thesen. Einfache Suche, gute Zitationsverfolgung.\nFrei zugänglich (Suche & Abstracts). Volltexte oft verlinkt (manchmal frei, manchmal Paywall).\nSehr hoch. Exzellenter Startpunkt, findet viel, auch Graue Literatur und Preprints. Qualitätskontrolle ist aber geringer als bei kuratierten Datenbanken.\n\n\narXiv.org\nDer Preprint-Server für Physik, Mathematik, Informatik (CS), Statistik, Elektrotechnik, Quantitative Biologie, Quantitative Finanzwissenschaften.\nVöllig frei zugänglich (Suche & Volltexte).\nSehr hoch. Hier werden die meisten bahnbrechenden Arbeiten im Bereich KI/ML zuerst veröffentlicht (als Preprints). Unverzichtbar für aktuelle Forschung, insbesondere aus der Informatik.\n\n\nPubMed Central (PMC)\nArchiv für biomedizinische und biowissenschaftliche Literatur. Enthält viele frei verfügbare Volltexte.\nVöllig frei zugänglich (Suche & viele Volltexte).\nMittel bis Hoch. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bereich Medizin/Biowissenschaften untersuchen wollen. PubMed (die Suchmaschine) ist ebenfalls frei, verlinkt aber auch auf nicht-freie Artikel.\n\n\nCORE\nAggregiert Open-Access-Forschungspapiere aus Repositorien und Zeitschriften weltweit.\nFrei zugänglich (Suche & Volltexte).\nHoch. Gute Quelle, um gezielt nach frei verfügbaren Volltexten zu suchen.\n\n\nDimensions\nUmfassende Datenbank, die Publikationen, Grants, Patente, klinische Studien etc. verknüpft. Bietet eine großzügige kostenlose Version.\nKostenlose Version verfügbar (Suche & Abstracts, einige Analysen). Erweiterte Funktionen sind kostenpflichtig.\nHoch. Bietet einen breiteren Kontext als nur Publikationen. Die kostenlose Version ist sehr leistungsfähig für die Recherche und das Finden relevanter Arbeiten.\n\n\nSemantic Scholar\nKI-gestützte Forschungsdatenbank, fokussiert auf Informatik und Biomedizin, expandiert aber. Bietet Zusammenfassungen und Zitationskontext.\nFrei zugänglich (Suche & Abstracts).\nHoch. Nutzt selbst KI zur Analyse von Papern, kann daher interessante Verbindungen aufzeigen. Gute Abdeckung im CS-Bereich.\n\n\nDBLP\nFokussiert auf Informatik-Publikationen (Konferenzen & Journale). Gut strukturiert nach Autoren und Publikationsorten.\nFrei zugänglich (Suche & Metadaten, oft Links zu Volltexten).\nHoch. Wenn der Fokus stark auf der Informatik-Perspektive liegt (Algorithmen, Systembau etc.).\n\n\nERIC (Education Resources Information Center)\nFührende Datenbank für Bildungsforschung.\nFrei zugänglich (Suche & viele Volltexte).\nMittel. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bildungskontext oder in der pädagogischen Forschung untersuchen.\n\n\nSSRN (Social Science Research Network)\nPreprint-Server primär für Sozial- und Geisteswissenschaften, aber auch andere Bereiche.\nFrei zugänglich (Suche & die meisten Volltexte).\nMittel. Kann relevant sein für Anwendungsfälle in den Sozialwissenschaften oder Diskussionen über die Auswirkungen von KI auf die Forschungspraxis in diesen Feldern.\n\n\n\nWichtiger Hinweis zu “frei verfügbar”:\n\nViele der “besten” kuratierten Datenbanken wie Scopus und Web of Science sind abonnementbasiert. Wenn Sie Zugang über eine Universität, Forschungseinrichtung oder Bibliothek haben, sollten Sie diese unbedingt ebenfalls nutzen, da sie oft eine höhere Qualitätssicherung und bessere Analysefunktionen bieten.\nInstitutionelle Repositorien: Viele Universitäten haben eigene Online-Archive (Repositorien), in denen Publikationen ihrer Forscher frei zugänglich sind. Diese sind oft über Google Scholar auffindbar, können aber auch direkt durchsucht werden.\n\nEmpfohlene Vorgehensweise:\n\nStarten Sie breit mit Google Scholar und arXiv, um ein Gefühl für die aktuelle Forschung zu bekommen.\nNutzen Sie spezifischere Suchbegriffe (aus der Tabelle) in diesen und anderen Datenbanken wie Dimensions oder Semantic Scholar.\nFiltern Sie nach Datum (z.B. Veröffentlichungen seit 2022 oder 2023).\nPrüfen Sie die Abstracts auf Relevanz.\nNutzen Sie die Zitationsverfolgung: Schauen Sie, welche neueren Arbeiten relevante ältere Paper zitieren (“Cited by” in Google Scholar) und welche Paper in den gefundenen Artikeln zitiert werden (Referenzliste, “Snowballing”).\nWenn Sie Zugang haben: Wiederholen Sie die wichtigsten Suchen in Scopus und/oder Web of Science.\n\nViel Erfolg bei Ihrer Recherche!\n\n\n\nToD: Viele interessante Papers zum Einsatz von “research workflow llm” mit Python etc. muss noch aufgearbeitet werden\n\n\n1.3.2 Recherche mit Deep Research Tools\nIn einem nächsten Schritt wurden die beiden Deep Research Tools verwendet um eine Literaturrecherche durchzuführen\n\n1.3.2.1 1. Prompt für eine Anfrage zum Thema Workflow für die Recherche mit Deep Research mit AI optimieren\nZunächst wurde der Prompt für eine AI Literaturrecherche mit Google AI Studio https://aistudio.google.com/ und dem Modell “Gemini 2.5 Pro Preview 03-25” (Stand 13.04.2025) optimiert:\n\n\n\n\n\n\nVerwendeter Prompt:\n\n\n\n\n\nOptimiere meinen Prompt zum Thema KI unterstützte Literaturrecherche in der Forschung. Wie kann ich das im Jahr 2025 optimalerweise machen? Es geht darum einen perfekten Workflow für den Einsatz sämtlicher relevanten Tools (LLMs aber auch Einsatz von Python etc.) zu bekommen, inkl. möglicher Gefahren und Chancen. Der ganze Workflow muss extrem ausführlich beschrieben sein und darf niemals hypothetische Tools oder Funktionen beinhalten, sondern muss ausschliesslich auf bekannte Funktionalitäten aufsetzen. Ich brauche einen vollständigen Prompt.\n\n\n\n\n\n\n\n\n\nAI Output\n\n\n\n\n\nOkay, hier ist ein optimierter Prompt, der darauf abzielt, einen detaillierten, praxisnahen und auf bekannten Technologien basierenden Workflow für die KI-gestützte Literaturrecherche im Jahr 2025 zu generieren. Dieser Prompt ist so formuliert, dass er einer leistungsstarken KI (wie GPT-4 oder Nachfolgemodellen) gegeben werden kann, um den gewünschten Workflow zu erstellen.\n\nPrompt:\nRolle: Du bist ein Experte für Forschungsmethodik, wissenschaftliches Arbeiten und den Einsatz von künstlicher Intelligenz in der Wissenschaft, mit einem Fokus auf den Stand der Technik Anfang 2025.\nAufgabe: Erstelle einen extrem ausführlichen, schrittweisen Workflow für die Durchführung einer umfassenden Literaturrecherche in einem beliebigen Forschungsfeld unter maximaler Nutzung von KI-Tools und -Technologien, wie sie bis Anfang 2025 realistischerweise etabliert und zugänglich sind. Der Workflow muss praxisorientiert sein und sich ausschließlich auf bekannte und verfügbare Funktionalitäten stützen. Hypothetische oder zukünftige, noch nicht entwickelte Tools oder Funktionen dürfen NICHT inkludiert werden.\nZielgruppe des Workflows: Wissenschaftler und Forscher (Doktoranden, Postdocs, etablierte Forscher).\nAnforderungen an den Workflow:\n\nDetaillierungsgrad: Jeder Schritt muss sehr detailliert beschrieben werden. Was genau ist zu tun? Welche spezifischen (Typen von) Tools werden eingesetzt? Wie interagieren die Tools? Wo ist menschliches Eingreifen und kritische Bewertung unerlässlich?\nPhasen: Gliedere den Workflow logisch in die typischen Phasen einer Literaturrecherche, z. B.:\n\nPhase 1: Planung & Definition (Forschungsfrage schärfen, Suchstrategie konzipieren)\nPhase 2: Suche & Identifikation (Papers finden)\nPhase 3: Screening & Auswahl (Relevanzprüfung)\nPhase 4: Datenextraktion & Analyse (Informationen aus Papers ziehen)\nPhase 5: Synthese & Berichterstattung (Ergebnisse zusammenfassen, Lücken identifizieren)\nPhase 6: Management & Aktualisierung (Referenzen verwalten, Recherche aktuell halten)\n\nTool-Integration: Beschreibe bei jedem relevanten Schritt konkret, wie folgende Tool-Kategorien (basierend auf Stand Anfang 2025) eingesetzt werden können:\n\nLarge Language Models (LLMs): z.B. GPT-4/Nachfolger, Claude-Modelle, Gemini/Bard für Aufgaben wie Brainstorming, Keyword-Generierung, Textzusammenfassung, Umformulierung, erste Syntheseentwürfe, Query-Optimierung. Spezifiziere die genaue Anwendung und die notwendige menschliche Verifikation.\nSpezialisierte KI-Such- und Analyseplattformen: z.B. Elicit, Semantic Scholar, Scite, ResearchRabbit, Connected Papers, Litmaps. Beschreibe deren spezifische Stärken (semantische Suche, Zitationsanalyse, Visualisierung von Forschungslandschaften, Frage-Antwort-Systeme basierend auf Papers).\nKI-gestützte Screening-Tools: z.B. Funktionen in systematischer Review-Software (Rayyan, Covidence) oder dedizierte Tools, die beim Priorisieren/Screenen von Abstracts helfen (basierend auf trainierten Algorithmen).\nReferenzmanagement-Software: z.B. Zotero, Mendeley, EndNote. Beschreibe auch mögliche KI-Integrationen (sofern bis Anfang 2025 Standard), z.B. für Duplikaterkennung oder Empfehlungen.\n(Optional aber empfohlen) Python-Skripte: Beschreibe einfache, realistische Anwendungsfälle für Forscher mit grundlegenden Python-Kenntnissen, z.B. zur Automatisierung von API-Abfragen (PubMed API, Crossref API), zur Deduplizierung von Suchergebnissen, zur einfachen Textanalyse (z.B. Frequenzanalysen von Keywords) oder zur Datenaufbereitung für Visualisierungen. Nutze bekannte Bibliotheken (z.B. requests, pandas, nltk, spacy, bibtexparser).\nTraditionelle Datenbanken: Betone, dass PubMed, Scopus, Web of Science etc. weiterhin essenziell sind und wie KI-Tools die Suche ergänzen, aber nicht ersetzen.\n\nChancen und Gefahren: Gehe bei jedem Schritt oder zumindest bei jeder Phase explizit und detailliert auf die spezifischen Chancen (z.B. Effizienzsteigerung, breitere Abdeckung, neue Einsichten) und Gefahren/Risiken (z.B. Halluzinationen von LLMs, Bias in Algorithmen, Verlust kritischer Fähigkeiten, Reproduzierbarkeitsprobleme, Datenschutz, “Filterblasen”-Effekte) des jeweiligen KI-Einsatzes ein. Gib konkrete Mitigationsstrategien an, wie Forscher diesen Gefahren begegnen können (z.B. Verifikationsprotokolle, Nutzung mehrerer Tools, kritische manuelle Prüfung).\nPraxisnähe und Reproduzierbarkeit: Der Workflow muss praktisch umsetzbar sein. Gib Hinweise zur Dokumentation des Vorgehens (welche Tools, Versionen, Prompts wurden verwendet?), um die Nachvollziehbarkeit zu gewährleisten.\nKeine Hypothetik: Stelle sicher, dass alle beschriebenen Tools und Funktionalitäten auf dem real existierenden Stand von Anfang 2025 basieren. Vermeide Aussagen wie “In Zukunft wird es möglich sein…” oder “Ein hypothetisches Tool könnte…”. Beziehe dich auf das, was bekannt ist.\nOutput-Format: Strukturiere die Antwort klar und übersichtlich, idealerweise mit nummerierten Schritten innerhalb der Phasen und klaren Unterabschnitten für Tools, Chancen, Gefahren und Mitigation pro Schritt/Phase.\n\nZusammenfassend: Erzeuge den bestmöglichen, detaillierten und realistischen Workflow für KI-gestützte Literaturrecherche (Stand Anfang 2025), der Forschern als praktische Anleitung dient und dabei Chancen und Risiken klar benennt und adressiert. Der Fokus liegt auf der Integration und dem Zusammenspiel bekannter Tools und Techniken.\n\nWarum dieser Prompt optimiert ist:\n\nKlare Rolle und Kontext: Definiert die Expertise der KI und den Zeitrahmen (Anfang 2025).\nSpezifische Anforderungen: Listet detailliert auf, was der Workflow enthalten muss (Phasen, Tool-Typen, Chancen/Gefahren, Detailgrad).\nFokus auf Realismus: Die Einschränkung “ausschließlich bekannte Funktionalitäten” und “keine Hypothetik” ist explizit und mehrfach genannt, um unrealistische Ergebnisse zu vermeiden.\nKonkrete Tool-Beispiele: Nennt Beispiele für jede Tool-Kategorie, um der KI eine klare Vorstellung zu geben, ohne sich auf nur ein Tool festzulegen.\nIntegration von Chancen/Gefahren: Fordert die Einbettung dieser Aspekte direkt in den Workflow, nicht nur als separaten Anhang. Verlangt auch Mitigationsstrategien.\nBetonung von Praxisnähe und Reproduzierbarkeit: Wichtige Aspekte für wissenschaftliches Arbeiten.\nStrukturvorgabe: Hilft der KI, einen gut organisierten Output zu liefern.\nZielgruppenorientierung: Stellt sicher, dass der Workflow für Forscher relevant ist.\n\nDieser Prompt sollte eine KI dazu bringen, einen sehr umfassenden und nützlichen Workflow zu generieren, der deinen Anforderungen entspricht."
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-hilfe-der-bishe-in-der-forschung-vorgeschlagenen-literatur",
    "href": "1_Literaturrecherche.html#recherche-mit-hilfe-der-bishe-in-der-forschung-vorgeschlagenen-literatur",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Recherche mit Hilfe der bishe in der Forschung vorgeschlagenen Literatur",
    "text": "1.5 Recherche mit Hilfe der bishe in der Forschung vorgeschlagenen Literatur\nToD: Viele interessante Papers zum Einsatz von “research workflow llm”\nhttps://www.biorxiv.org/content/10.1101/2025.02.23.639768v1.full.pdf\n(muss noch ausprobiert werden)"
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-zum-thema",
    "href": "1_Literaturrecherche.html#recherche-zum-thema",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Recherche zum Thema",
    "text": "1.5 Recherche zum Thema\n\n1.5.1 Recherche mit Deep Research\n\n\n\n\nGusenbauer, M., & Gauster, S. P. (2025). How to search for literature in systematic reviews and meta-analyses: A comprehensive step-by-step guide. Technological Forecasting and Social Change, 212, 123833. https://doi.org/10.1016/j.techfore.2024.123833\n\n\nKhalifa, M., & Albadawy, M. (2024). Using artificial intelligence in academic writing and research: An essential productivity tool. Computer Methods and Programs in Biomedicine Update, 5, 100145. https://doi.org/10.1016/j.cmpbup.2024.100145\n\n\nSeth, I., Lim, B., Xie, Y., Ross, R. J., Cuomo, R., & Rozen, W. M. (2025). Artificial intelligence versus human researcher performance for systematic literature searches: A study focusing on the surgical management of base of thumb arthritis. Plastic and Aesthetic Research. https://doi.org/10.20517/2347-9264.2024.99\n\n\nWu, J., Zhu, J., & Liu, Y. (2025). Agentic reasoning: Reasoning LLMs with tools for the deep research. arXiv. https://doi.org/10.48550/ARXIV.2502.04644"
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-hilfe-der-bisher-in-der-forschung-vorgeschlagenen-literatur",
    "href": "1_Literaturrecherche.html#recherche-mit-hilfe-der-bisher-in-der-forschung-vorgeschlagenen-literatur",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Recherche mit Hilfe der bisher in der Forschung vorgeschlagenen Literatur",
    "text": "1.5 Recherche mit Hilfe der bisher in der Forschung vorgeschlagenen Literatur\nToD: Viele interessante Papers zum Einsatz von “research workflow llm”\nhttps://www.biorxiv.org/content/10.1101/2025.02.23.639768v1.full.pdf\n(muss noch ausprobiert werden)"
  },
  {
    "objectID": "1_Literaturrecherche.html#auswahl-der-methodologie-für-die-recherche",
    "href": "1_Literaturrecherche.html#auswahl-der-methodologie-für-die-recherche",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.3 Auswahl der Methodologie für die Recherche",
    "text": "1.3 Auswahl der Methodologie für die Recherche\n\n1.3.1 Menschliche Recherche nach Forschungsliteratur zum Thema “KI unterstützte Suche nach Forschungsliteratur”\nDie Literatursuche erfolgte zunächst unsystematisch und explorativ in einem Scoping Prozess. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. In diesem Scoping Prozess scheinen auch die besonderen Stärken der KI zu liegen (Gusenbauer & Gauster, 2025). Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung radikal zu verändern (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es auch vielversprechende Open Source Ansätze in diesem Bereich zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025). Die erste Scopingsuche war wenig erfolgreich, deshalb wurde in einem nächsten Schritt des Prozesses versucht die Suchbegriffe etwas zu verbessern, dazu wurde folgendes Prompting mit Google AI Studio verwendet um die Suche zu optimieren .\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI unterstützte Recherche aber auch konkreten Tools wie “ChatGPT”, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchparameter für Google Scholar und ähnliche Suchmaschinen als praktische Tabelle (verschiedene Alternativssuchmöglichkeiten) und anschliessend einen Überblick über die wichtigsten Datenbanken, die ich mir anschauen sollte.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier sind optimierte Suchparameter und eine Übersicht über relevante Forschungsdatenbanken für Ihre Suche nach Workflows und Tools im Bereich KI-unterstützte Recherche.\n1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\n\n\n\n\n\n\n\n\nFokus / Ziel\nSuchbegriffe (Beispiele für Google Scholar & Co.)\nHinweise / Strategie\n\n\nBreit: KI & Recherche allgemein\n“artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review”\nStartpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten.\n\n\nFokus: KI-Unterstützung im Workflow\n“AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review”\nKonzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews.\n\n\nFokus: Generative KI / LLMs in Recherche\n“Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery”\nZielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen.\n\n\nSpezifisch: ChatGPT in Recherche\n“ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”)\nSucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen.\n\n\nSpezifisch: OpenAI (als Technologiegeber)\n“OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”)\nVorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research”\n\n\nSpezifisch: Andere Tools (Beispiel)\n“Deep Research” AND “AI” AND (“research tool” OR “literature review”)\nErsetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung.\n\n\nFokus: KI-Tools für Recherche\n“AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform”\nSucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung.\n\n\nKombination: Workflow & Spezifisches Tool\n(“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”)\nKombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools.\n\n\nAlternative Formulierungen\n“intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search”\nFängt alternative Bezeichnungen und Konzepte auf.\n\n\n\nWichtige Tipps zur Suche:\n\n**Anführungszeichen (” “):** Verwenden Sie sie für exakte Phrasen (z.B.”literature review”).\nOR Operator: Muss oft großgeschrieben werden. Dient zur Suche nach Alternativen (z.B. AI OR “artificial intelligence”). Klammern () können zur Gruppierung genutzt werden: (AI OR “artificial intelligence”) AND (“literature review” OR “research workflow”).\nAND Operator: Verbindet verschiedene Konzepte. Oft implizit (Leerzeichen genügt).\nPlatzhalter (*): Manche Datenbanken erlauben Wildcards (z.B. research* findet research, researcher, researching). Mit Vorsicht verwenden, kann unspezifisch werden.\nFilter nutzen: Fast alle Datenbanken erlauben Filter nach Publikationsdatum (sehr wichtig bei diesem schnelllebigen Thema!), Dokumenttyp (Journal Article, Conference Paper, Review etc.), Fachgebiet etc. Nutzen Sie insbesondere den Datumsfilter (z.B. letzte 1-3 Jahre).\nVariieren: Keine einzelne Suche ist perfekt. Probieren Sie verschiedene Kombinationen aus.\n\n2. Wichtige frei verfügbare Forschungsdatenbanken\nHier ist eine Liste der wichtigsten Datenbanken, wobei der “freie Zugang” oft bedeutet, dass die Suche und Abstracts frei sind, der Volltext aber hinter einer Paywall liegen kann (oft über Universitäts-/Institutionsbibliotheken zugänglich).\n\n\n\n\n\n\n\n\n\nDatenbank\nFokus / Beschreibung\nZugang\nRelevanz für Ihr Thema\n\n\nGoogle Scholar\nSehr breite Abdeckung über alle Disziplinen, inklusive Preprints, Konferenzbeiträge, Thesen. Einfache Suche, gute Zitationsverfolgung.\nFrei zugänglich (Suche & Abstracts). Volltexte oft verlinkt (manchmal frei, manchmal Paywall).\nSehr hoch. Exzellenter Startpunkt, findet viel, auch Graue Literatur und Preprints. Qualitätskontrolle ist aber geringer als bei kuratierten Datenbanken.\n\n\narXiv.org\nDer Preprint-Server für Physik, Mathematik, Informatik (CS), Statistik, Elektrotechnik, Quantitative Biologie, Quantitative Finanzwissenschaften.\nVöllig frei zugänglich (Suche & Volltexte).\nSehr hoch. Hier werden die meisten bahnbrechenden Arbeiten im Bereich KI/ML zuerst veröffentlicht (als Preprints). Unverzichtbar für aktuelle Forschung, insbesondere aus der Informatik.\n\n\nPubMed Central (PMC)\nArchiv für biomedizinische und biowissenschaftliche Literatur. Enthält viele frei verfügbare Volltexte.\nVöllig frei zugänglich (Suche & viele Volltexte).\nMittel bis Hoch. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bereich Medizin/Biowissenschaften untersuchen wollen. PubMed (die Suchmaschine) ist ebenfalls frei, verlinkt aber auch auf nicht-freie Artikel.\n\n\nCORE\nAggregiert Open-Access-Forschungspapiere aus Repositorien und Zeitschriften weltweit.\nFrei zugänglich (Suche & Volltexte).\nHoch. Gute Quelle, um gezielt nach frei verfügbaren Volltexten zu suchen.\n\n\nDimensions\nUmfassende Datenbank, die Publikationen, Grants, Patente, klinische Studien etc. verknüpft. Bietet eine großzügige kostenlose Version.\nKostenlose Version verfügbar (Suche & Abstracts, einige Analysen). Erweiterte Funktionen sind kostenpflichtig.\nHoch. Bietet einen breiteren Kontext als nur Publikationen. Die kostenlose Version ist sehr leistungsfähig für die Recherche und das Finden relevanter Arbeiten.\n\n\nSemantic Scholar\nKI-gestützte Forschungsdatenbank, fokussiert auf Informatik und Biomedizin, expandiert aber. Bietet Zusammenfassungen und Zitationskontext.\nFrei zugänglich (Suche & Abstracts).\nHoch. Nutzt selbst KI zur Analyse von Papern, kann daher interessante Verbindungen aufzeigen. Gute Abdeckung im CS-Bereich.\n\n\nDBLP\nFokussiert auf Informatik-Publikationen (Konferenzen & Journale). Gut strukturiert nach Autoren und Publikationsorten.\nFrei zugänglich (Suche & Metadaten, oft Links zu Volltexten).\nHoch. Wenn der Fokus stark auf der Informatik-Perspektive liegt (Algorithmen, Systembau etc.).\n\n\nERIC (Education Resources Information Center)\nFührende Datenbank für Bildungsforschung.\nFrei zugänglich (Suche & viele Volltexte).\nMittel. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bildungskontext oder in der pädagogischen Forschung untersuchen.\n\n\nSSRN (Social Science Research Network)\nPreprint-Server primär für Sozial- und Geisteswissenschaften, aber auch andere Bereiche.\nFrei zugänglich (Suche & die meisten Volltexte).\nMittel. Kann relevant sein für Anwendungsfälle in den Sozialwissenschaften oder Diskussionen über die Auswirkungen von KI auf die Forschungspraxis in diesen Feldern.\n\n\n\nWichtiger Hinweis zu “frei verfügbar”:\n\nViele der “besten” kuratierten Datenbanken wie Scopus und Web of Science sind abonnementbasiert. Wenn Sie Zugang über eine Universität, Forschungseinrichtung oder Bibliothek haben, sollten Sie diese unbedingt ebenfalls nutzen, da sie oft eine höhere Qualitätssicherung und bessere Analysefunktionen bieten.\nInstitutionelle Repositorien: Viele Universitäten haben eigene Online-Archive (Repositorien), in denen Publikationen ihrer Forscher frei zugänglich sind. Diese sind oft über Google Scholar auffindbar, können aber auch direkt durchsucht werden.\n\nEmpfohlene Vorgehensweise:\n\nStarten Sie breit mit Google Scholar und arXiv, um ein Gefühl für die aktuelle Forschung zu bekommen.\nNutzen Sie spezifischere Suchbegriffe (aus der Tabelle) in diesen und anderen Datenbanken wie Dimensions oder Semantic Scholar.\nFiltern Sie nach Datum (z.B. Veröffentlichungen seit 2022 oder 2023).\nPrüfen Sie die Abstracts auf Relevanz.\nNutzen Sie die Zitationsverfolgung: Schauen Sie, welche neueren Arbeiten relevante ältere Paper zitieren (“Cited by” in Google Scholar) und welche Paper in den gefundenen Artikeln zitiert werden (Referenzliste, “Snowballing”).\nWenn Sie Zugang haben: Wiederholen Sie die wichtigsten Suchen in Scopus und/oder Web of Science.\n\nViel Erfolg bei Ihrer Recherche!\n\n\n\nToDo: Viele interessante Papers zum Einsatz von “research workflow llm” mit Python etc. muss noch aufgearbeitet werden\n\n\n1.3.2 Recherche mit Deep Research Tools nach “KI unterstützte Suche nach Forschungsliteratur”\nIn einem nächsten Schritt wurden die beiden Deep Research Tools verwendet um eine Literaturrecherche durchzuführen. Auch wenn sich eine Promptoptimierung angeboten hätte, ist Deep Research zurzeit noch nicht lange genug veröffentlich, dass sich mögliche optimierte Strategien bereits zeigen. Deshalb wurde der folgende Befehl verwendet, welcher teilweise den Output von oben. Verwendet wurde in Google Gemini und ChatGPT mit Deep Research der folgende Input:\n\n\n\n\n\n\nVerwendeter Prompt in Gemini Advanced (Deep Research mit 2.5 Pro) und Open AI Deep Research):\n\n\n\n\n\nErstelle mir einen möglichst ausführlichen Forschungsbericht mit reichhaltiger Literatur zum Thema KI unterstützte Literaturrecherche in der Forschung. Ausschliesslich neuste Forschungsliteratur benutzen. Hier sind die Suchbegriffe: 1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\nFokus / Ziel Suchbegriffe (Beispiele für Google Scholar & Co.) Hinweise / Strategie Breit: KI & Recherche allgemein “artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review” Startpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten. Fokus: KI-Unterstützung im Workflow “AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review” Konzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews. Fokus: Generative KI / LLMs in Recherche “Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery” Zielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen. Spezifisch: ChatGPT in Recherche “ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”) Sucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen. Spezifisch: OpenAI (als Technologiegeber) “OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”) Vorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research” Spezifisch: Andere Tools (Beispiel) “Deep Research” AND “AI” AND (“research tool” OR “literature review”) Ersetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung. Fokus: KI-Tools für Recherche “AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform” Sucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung. Kombination: Workflow & Spezifisches Tool (“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”) Kombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools. Alternative Formulierungen “intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search” Fängt alternative Bezeichnungen und Konzepte auf.\n\n\n\nZusätzlich wurde bei ChatGPT noch angefügt bei der Nachfrage “Den kompletten Bericht auf Deutsch mit der kompletten Literatur”.\n\n\n\n\n\n\nVerwendeter Prompt in Gemini Advanced (Deep Research mit 2.5 Pro) und Open AI Deep Research):"
  },
  {
    "objectID": "1_Literaturrecherche.html#literatur",
    "href": "1_Literaturrecherche.html#literatur",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.8 Literatur",
    "text": "1.8 Literatur\n\n\n\n\nGusenbauer, M., & Gauster, S. P. (2025). How to search for literature in systematic reviews and meta-analyses: A comprehensive step-by-step guide. Technological Forecasting and Social Change, 212, 123833. https://doi.org/10.1016/j.techfore.2024.123833\n\n\nKhalifa, M., & Albadawy, M. (2024). Using artificial intelligence in academic writing and research: An essential productivity tool. Computer Methods and Programs in Biomedicine Update, 5, 100145. https://doi.org/10.1016/j.cmpbup.2024.100145\n\n\nSeth, I., Lim, B., Xie, Y., Ross, R. J., Cuomo, R., & Rozen, W. M. (2025). Artificial intelligence versus human researcher performance for systematic literature searches: A study focusing on the surgical management of base of thumb arthritis. Plastic and Aesthetic Research. https://doi.org/10.20517/2347-9264.2024.99\n\n\nWu, J., Zhu, J., & Liu, Y. (2025). Agentic reasoning: Reasoning LLMs with tools for the deep research. arXiv. https://doi.org/10.48550/ARXIV.2502.04644"
  },
  {
    "objectID": "1_Literaturrecherche.html#auswahl-der-methodik-für-die-recherche",
    "href": "1_Literaturrecherche.html#auswahl-der-methodik-für-die-recherche",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.3 Auswahl der Methodik für die Recherche",
    "text": "1.3 Auswahl der Methodik für die Recherche\n\n1.3.1 Menschliche Recherche nach Forschungsliteratur zum Thema “KI unterstützte Suche nach Forschungsliteratur”\nDie Literatursuche erfolgte zunächst unsystematisch und explorativ in einem Scoping Prozess. Um die Literaturrecherche mit KI Tools zu unterstützen, wurde zuerst Arvix und Google Scholar durchforstet nach Preprints und neuen Artikeln zum Thema KI unterstützte Suche bei der Erstellung von Literature Reviews. In diesem Scoping Prozess scheinen auch die besonderen Stärken der KI zu liegen (Gusenbauer & Gauster, 2025). Die Literatur lässt sich grob in die beiden Bereiche proprietäre und selbst entwicklte Tools / Methoden unterteilen. Hier erfolt eine Beschränkung auf den Einsatz von verfügbaren proprietären Tools. Als erstes werden KI-gestützte Suchmaschinen wie Elicit und Consensus erwähnt. Deren Einsatz ist möglicherweise vielversprechend, es gibt es aber noch Herausforderungen in Bezug auf Präzision und Vollständigkeit der Suchergebnisse im Vergleich zu manuellen Methoden.(Seth et al., 2025) Eine andere Familie von Tools sind die so genannten Deep Research Tools. Diese ebenfalls proprietären Tools von Open AI und Google zeigen ansatzweise agentisches Verhalten und brauchen für einen Suchvorgang häufig länger, liefern aber vollständige Texte. Durch die schnelle Weiterentwicklung und dem kürzlichen Erscheinen von Deep Research von Google liegen m.E. bislang noch keine Forschungsergebnisse vor. Jedoch scheinen beide Tools nach wie vor unter den Large Language typischen und ungelösten “Halluzinationen” zu leiden , auch wenn sie wie andere LLM Systeme Potential haben die Forschung radikal zu verändern (Khalifa & Albadawy, 2024) . In diesem Zusammenhang scheint es erwähnenswert, dass es auch vielversprechende Open Source Ansätze in diesem Bereich zu geben scheint, die möglicherweise diese Probleme verringern können, indem sie ein zusätzliches Retrieval-Augmented Generation System (RAG) verwenden (Wu et al., 2025). Die erste Scopingsuche war wenig erfolgreich, deshalb wurde in einem nächsten Schritt des Prozesses versucht die Suchbegriffe etwas zu verbessern, dazu wurde folgendes Prompting mit Google AI Studio verwendet um die Suche zu optimieren .\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nIch möchte in den wichtigsten frei verfügbaren Forschungsdatenbanken suchen nach Workflows zum Thema AI unterstützte Recherche aber auch konkreten Tools wie “ChatGPT”, “Open AI” “Deep Research” etc. Erstelle mir die optimale Suchparameter für Google Scholar und ähnliche Suchmaschinen als praktische Tabelle (verschiedene Alternativssuchmöglichkeiten) und anschliessend einen Überblick über die wichtigsten Datenbanken, die ich mir anschauen sollte.\n\n\n\n\n\n\n\n\n\nOutput von Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\nOkay, hier sind optimierte Suchparameter und eine Übersicht über relevante Forschungsdatenbanken für Ihre Suche nach Workflows und Tools im Bereich KI-unterstützte Recherche.\n1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\n\n\n\n\n\n\n\n\nFokus / Ziel\nSuchbegriffe (Beispiele für Google Scholar & Co.)\nHinweise / Strategie\n\n\nBreit: KI & Recherche allgemein\n“artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review”\nStartpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten.\n\n\nFokus: KI-Unterstützung im Workflow\n“AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review”\nKonzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews.\n\n\nFokus: Generative KI / LLMs in Recherche\n“Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery”\nZielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen.\n\n\nSpezifisch: ChatGPT in Recherche\n“ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”)\nSucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen.\n\n\nSpezifisch: OpenAI (als Technologiegeber)\n“OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”)\nVorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research”\n\n\nSpezifisch: Andere Tools (Beispiel)\n“Deep Research” AND “AI” AND (“research tool” OR “literature review”)\nErsetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung.\n\n\nFokus: KI-Tools für Recherche\n“AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform”\nSucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung.\n\n\nKombination: Workflow & Spezifisches Tool\n(“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”)\nKombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools.\n\n\nAlternative Formulierungen\n“intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search”\nFängt alternative Bezeichnungen und Konzepte auf.\n\n\n\nWichtige Tipps zur Suche:\n\n**Anführungszeichen (” “):** Verwenden Sie sie für exakte Phrasen (z.B.”literature review”).\nOR Operator: Muss oft großgeschrieben werden. Dient zur Suche nach Alternativen (z.B. AI OR “artificial intelligence”). Klammern () können zur Gruppierung genutzt werden: (AI OR “artificial intelligence”) AND (“literature review” OR “research workflow”).\nAND Operator: Verbindet verschiedene Konzepte. Oft implizit (Leerzeichen genügt).\nPlatzhalter (*): Manche Datenbanken erlauben Wildcards (z.B. research* findet research, researcher, researching). Mit Vorsicht verwenden, kann unspezifisch werden.\nFilter nutzen: Fast alle Datenbanken erlauben Filter nach Publikationsdatum (sehr wichtig bei diesem schnelllebigen Thema!), Dokumenttyp (Journal Article, Conference Paper, Review etc.), Fachgebiet etc. Nutzen Sie insbesondere den Datumsfilter (z.B. letzte 1-3 Jahre).\nVariieren: Keine einzelne Suche ist perfekt. Probieren Sie verschiedene Kombinationen aus.\n\n2. Wichtige frei verfügbare Forschungsdatenbanken\nHier ist eine Liste der wichtigsten Datenbanken, wobei der “freie Zugang” oft bedeutet, dass die Suche und Abstracts frei sind, der Volltext aber hinter einer Paywall liegen kann (oft über Universitäts-/Institutionsbibliotheken zugänglich).\n\n\n\n\n\n\n\n\n\nDatenbank\nFokus / Beschreibung\nZugang\nRelevanz für Ihr Thema\n\n\nGoogle Scholar\nSehr breite Abdeckung über alle Disziplinen, inklusive Preprints, Konferenzbeiträge, Thesen. Einfache Suche, gute Zitationsverfolgung.\nFrei zugänglich (Suche & Abstracts). Volltexte oft verlinkt (manchmal frei, manchmal Paywall).\nSehr hoch. Exzellenter Startpunkt, findet viel, auch Graue Literatur und Preprints. Qualitätskontrolle ist aber geringer als bei kuratierten Datenbanken.\n\n\narXiv.org\nDer Preprint-Server für Physik, Mathematik, Informatik (CS), Statistik, Elektrotechnik, Quantitative Biologie, Quantitative Finanzwissenschaften.\nVöllig frei zugänglich (Suche & Volltexte).\nSehr hoch. Hier werden die meisten bahnbrechenden Arbeiten im Bereich KI/ML zuerst veröffentlicht (als Preprints). Unverzichtbar für aktuelle Forschung, insbesondere aus der Informatik.\n\n\nPubMed Central (PMC)\nArchiv für biomedizinische und biowissenschaftliche Literatur. Enthält viele frei verfügbare Volltexte.\nVöllig frei zugänglich (Suche & viele Volltexte).\nMittel bis Hoch. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bereich Medizin/Biowissenschaften untersuchen wollen. PubMed (die Suchmaschine) ist ebenfalls frei, verlinkt aber auch auf nicht-freie Artikel.\n\n\nCORE\nAggregiert Open-Access-Forschungspapiere aus Repositorien und Zeitschriften weltweit.\nFrei zugänglich (Suche & Volltexte).\nHoch. Gute Quelle, um gezielt nach frei verfügbaren Volltexten zu suchen.\n\n\nDimensions\nUmfassende Datenbank, die Publikationen, Grants, Patente, klinische Studien etc. verknüpft. Bietet eine großzügige kostenlose Version.\nKostenlose Version verfügbar (Suche & Abstracts, einige Analysen). Erweiterte Funktionen sind kostenpflichtig.\nHoch. Bietet einen breiteren Kontext als nur Publikationen. Die kostenlose Version ist sehr leistungsfähig für die Recherche und das Finden relevanter Arbeiten.\n\n\nSemantic Scholar\nKI-gestützte Forschungsdatenbank, fokussiert auf Informatik und Biomedizin, expandiert aber. Bietet Zusammenfassungen und Zitationskontext.\nFrei zugänglich (Suche & Abstracts).\nHoch. Nutzt selbst KI zur Analyse von Papern, kann daher interessante Verbindungen aufzeigen. Gute Abdeckung im CS-Bereich.\n\n\nDBLP\nFokussiert auf Informatik-Publikationen (Konferenzen & Journale). Gut strukturiert nach Autoren und Publikationsorten.\nFrei zugänglich (Suche & Metadaten, oft Links zu Volltexten).\nHoch. Wenn der Fokus stark auf der Informatik-Perspektive liegt (Algorithmen, Systembau etc.).\n\n\nERIC (Education Resources Information Center)\nFührende Datenbank für Bildungsforschung.\nFrei zugänglich (Suche & viele Volltexte).\nMittel. Relevant, wenn Sie den Einsatz von KI-Recherchetools im Bildungskontext oder in der pädagogischen Forschung untersuchen.\n\n\nSSRN (Social Science Research Network)\nPreprint-Server primär für Sozial- und Geisteswissenschaften, aber auch andere Bereiche.\nFrei zugänglich (Suche & die meisten Volltexte).\nMittel. Kann relevant sein für Anwendungsfälle in den Sozialwissenschaften oder Diskussionen über die Auswirkungen von KI auf die Forschungspraxis in diesen Feldern.\n\n\n\nWichtiger Hinweis zu “frei verfügbar”:\n\nViele der “besten” kuratierten Datenbanken wie Scopus und Web of Science sind abonnementbasiert. Wenn Sie Zugang über eine Universität, Forschungseinrichtung oder Bibliothek haben, sollten Sie diese unbedingt ebenfalls nutzen, da sie oft eine höhere Qualitätssicherung und bessere Analysefunktionen bieten.\nInstitutionelle Repositorien: Viele Universitäten haben eigene Online-Archive (Repositorien), in denen Publikationen ihrer Forscher frei zugänglich sind. Diese sind oft über Google Scholar auffindbar, können aber auch direkt durchsucht werden.\n\nEmpfohlene Vorgehensweise:\n\nStarten Sie breit mit Google Scholar und arXiv, um ein Gefühl für die aktuelle Forschung zu bekommen.\nNutzen Sie spezifischere Suchbegriffe (aus der Tabelle) in diesen und anderen Datenbanken wie Dimensions oder Semantic Scholar.\nFiltern Sie nach Datum (z.B. Veröffentlichungen seit 2022 oder 2023).\nPrüfen Sie die Abstracts auf Relevanz.\nNutzen Sie die Zitationsverfolgung: Schauen Sie, welche neueren Arbeiten relevante ältere Paper zitieren (“Cited by” in Google Scholar) und welche Paper in den gefundenen Artikeln zitiert werden (Referenzliste, “Snowballing”).\nWenn Sie Zugang haben: Wiederholen Sie die wichtigsten Suchen in Scopus und/oder Web of Science.\n\nViel Erfolg bei Ihrer Recherche!\n\n\n\nToDo: Viele interessante Papers zum Einsatz von “research workflow llm” mit Python etc. muss noch aufgearbeitet werden https://agentlaboratory.github.io/\n\n\n1.3.2 Recherche mit Deep Research Tools nach “KI unterstützte Suche nach Forschungsliteratur”\nIn einem nächsten Schritt wurden die beiden Deep Research Tools verwendet um eine Literaturrecherche durchzuführen. Auch wenn sich eine Verfeinerung des Prompts angeboten hätte, ist Deep Research zurzeit noch nicht lange genug veröffentlich, dass sich mögliche optimierte Strategien bereits zeigen. Deshalb wurde der folgende Befehl verwendet, welcher teilweise den Output von oben entspricht. Verwendet wurde in Google Gemini und ChatGPT mit Deep Research der folgende Input (Zusätzlich wurde bei ChatGPT noch angefügt bei der Nachfrage “Den kompletten Bericht auf Deutsch mit der kompletten Literatur”.):\n\n\n\n\n\n\nVerwendeter Prompt in Gemini Advanced (Deep Research mit 2.5 Pro) und ChatGPT Deep Research:\n\n\n\n\n\nErstelle mir einen möglichst ausführlichen Forschungsbericht mit reichhaltiger Literatur zum Thema KI unterstützte Literaturrecherche in der Forschung. Ausschliesslich neuste Forschungsliteratur benutzen. Hier sind die Suchbegriffe: 1. Optimierte Suchparameter (als Tabelle)\nDiese Tabelle bietet verschiedene Suchstring-Varianten, von breit bis spezifisch. Sie können diese kombinieren und anpassen. In den meisten Datenbanken funktioniert AND implizit (Leerzeichen), OR muss explizit angegeben werden, und Phrasen stehen in Anführungszeichen (“).\nFokus / Ziel Suchbegriffe (Beispiele für Google Scholar & Co.) Hinweise / Strategie Breit: KI & Recherche allgemein “artificial intelligence” OR AI OR “machine learning” AND “research process” OR “information retrieval” OR “literature review” Startpunkt, um das Feld breit zu erfassen. Kombiniert allgemeine KI-Begriffe mit Rechercheaktivitäten. Fokus: KI-Unterstützung im Workflow “AI-assisted” OR “AI-supported” OR “AI-driven” AND “research workflow” OR “literature review workflow” OR “systematic review” Konzentriert sich auf die Unterstützung durch KI im Forschungsprozess, insbesondere bei etablierten Methoden wie systematischen Reviews. Fokus: Generative KI / LLMs in Recherche “Generative AI” OR “Large Language Models” OR LLM AND “research” OR “academic research” OR “scientific writing” OR “knowledge discovery” Zielt auf neuere Entwicklungen mit Modellen wie GPT ab. Verbindet diese Technologien mit Forschungsanwendungen. Spezifisch: ChatGPT in Recherche “ChatGPT” AND (“research workflow” OR “literature review” OR “academic writing” OR “research assistant” OR “systematic review”) Sucht gezielt nach Studien, die den Einsatz von ChatGPT im Forschungskontext untersuchen. Spezifisch: OpenAI (als Technologiegeber) “OpenAI” AND (“research tool” OR “literature analysis” OR “scientific discovery”) Vorsicht: Kann auch Treffer zur Firma OpenAI selbst liefern. Präziser mit Fokus auf Anwendungen. Evtl. kombinieren: “OpenAI” AND “ChatGPT” AND “research” Spezifisch: Andere Tools (Beispiel) “Deep Research” AND “AI” AND (“research tool” OR “literature review”) Ersetzen Sie “Deep Research” durch andere bekannte Tool-Namen. Anführungszeichen sind wichtig, um genau diesen Namen zu finden. Kontext (AI, research tool) hilft zur Abgrenzung. Fokus: KI-Tools für Recherche “AI research tool” OR “AI literature review tool” OR “AI knowledge discovery platform” Sucht nach der Beschreibung von Werkzeugen selbst, nicht nur deren Anwendung. Kombination: Workflow & Spezifisches Tool (“research workflow” OR “literature review”) AND (“ChatGPT” OR “Generative AI” OR “LLM”) Kombiniert den Prozess (Workflow) mit den spezifischen Technologien/Tools. Alternative Formulierungen “intelligent research assistant” OR “AI co-pilot for research” OR “automated literature search” Fängt alternative Bezeichnungen und Konzepte auf."
  },
  {
    "objectID": "1_Literaturrecherche.html#durchführung-der-recherche",
    "href": "1_Literaturrecherche.html#durchführung-der-recherche",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.4 Durchführung der Recherche",
    "text": "1.4 Durchführung der Recherche"
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-deep-research-tools-zur-forschungsfrage",
    "href": "1_Literaturrecherche.html#recherche-mit-deep-research-tools-zur-forschungsfrage",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Recherche mit Deep Research Tools zur Forschungsfrage",
    "text": "1.5 Recherche mit Deep Research Tools zur Forschungsfrage\nDie weitergehende Forschung zu diesen beiden Tools noch fehlt, wurde der Report ohne weitere Instruktionen sowohl für Deep Research von Open AI und Deep Research (11.04.2025) direkt verwendet:\n\n\n\n\n\n\nVerwendeter Prompt in Gemini Advanced (Deep Research mit 2.5 Pro) und Open AI Deep Research:\n\n\n\n\n\nFühre eine allumfassende Literaturrecherche zum Zusammenhang zwischen kognitiver Anstrengung (cognitive effort) und kognitiver Performance durch. Konzentriere dich dabei primär auf psychologische Studien und Modelle, beziehe aber sämtliche relevante Erkenntnisse aus angrenzenden Disziplinen wie den Kognitions- und Neurowissenschaften, Wirtschaftswissenschaften, Biologie etc. mit ein. Priorisiere bei der Recherche Publikationen aus hochrangigen, peer-reviewten Fachzeitschriften (High-Impact Journals). Die Recherche soll folgende Kernfragen beleuchten: Linearität: Gibt es Evidenz für einen direkten, linearen Zusammenhang zwischen dem Grad der unmittelbaren Anstrengung und dem Niveau der kognitiven Leistung? Nicht-Linearität & optimale Anstrengung: Welche Belege gibt es für nicht-lineare Zusammenhänge (z.B. U-förmig, invers U-förmig)? Unter welchen Umständen führt mehr Anstrengung nicht zu besserer Leistung oder sogar zu einer Leistungsverschlechterung? Moderierende Faktoren: Welche Variablen beeinflussen die Beziehung zwischen Anstrengung und Leistung maßgeblich (z.B. Aufgabenkomplexität, Aufgabentyp, Motivation, individuelle Fähigkeiten, Müdigkeit, Alter, wahrgenommene Selbstwirksamkeit)? Theoretische Grundlagen: Welche etablierten Theorien oder Modelle werden herangezogen, um diesen Zusammenhang zu erklären? Messung: Wie werden ‘momentane kognitive Anstrengung’ und ‘kognitive Performance’ in diesen Studien typischerweise operationalisiert und gemessen? Bitte synthetisiere die wichtigsten Ergebnisse äusserst ausführlich (10000 Seiten) , identifiziere zentrale Debatten oder Forschungslücken und erstelle eine Liste der relevantesten Schlüsselpublikationen (inklusive wichtiger Reviews oder Meta-Analysen). Wenn möglich, gib die Referenzen im APA 7 Format an oder stelle die Informationen so bereit, dass sie leicht in dieses Format überführt werden können. (1) Recherchiere etablierte Definitionen und Konzepte von kognitiver Anstrengung und kognitiver Leistung in der Psychologie, den Kognitions- und Neurowissenschaften sowie sämtlichen angrenzenden relevanten Disziplinen. (2) Suche nach empirischen Studien und Meta-Analysen, die einen linearen Zusammenhang zwischen dem Ausmaß kognitiver Anstrengung und dem Niveau kognitiver Leistung untersuchen. (3) Identifiziere Forschungsarbeiten, die nicht-lineare Beziehungen (z.B. invertierte U-Form) zwischen kognitiver Anstrengung und Leistung belegen, einschließlich Studien zu Phänomenen wie “Choking under Pressure” oder Leistungsabfall bei Überanstrengung. (4) Untersuche Studien, die Moderatoren der Beziehung zwischen kognitiver Anstrengung und Leistung analysieren, darunter: (a) Aufgabenmerkmale (z.B. Komplexität, Typ, Dauer) (b) Individuelle Unterschiede (z.B. Motivation, Fähigkeiten, Alter, Ermüdung, Selbstwirksamkeit) (c) Kontextfaktoren (z.B. Stress, Anreize) (5) Recherchiere zentrale theoretische Modelle, die zur Erklärung des Zusammenhangs zwischen kognitiver Anstrengung und Leistung herangezogen werden. Analysiere ihre Grundannahmen und Vorhersagen. (6) Finde heraus, wie kognitive Anstrengung (z.B. subjektive Bewertungen, physiologische Maße wie Pupillometrie, Herzratenvariabilität, EEG/fMRT) und kognitive Leistung (z.B. Genauigkeit, Reaktionszeit) in der Forschung typischerweise operationalisiert und gemessen werden. (7) Synthetisiere die Ergebnisse der Recherche, identifiziere zentrale wissenschaftliche Debatten, widersprüchliche Befunde und offene Forschungsfragen im Themenbereich. (8) Erstelle eine Liste der Schlüsselpublikationen (einschließlich wichtiger Übersichtsarbeiten und Meta-Analysen) zum Thema und extrahiere die bibliographischen Informationen (Autoren, Jahr, Titel, Zeitschrift, DOI), um eine Formatierung im APA-7-Stil zu ermöglichen."
  },
  {
    "objectID": "1_Literaturrecherche.html#explorative-recherche-mit-deep-research-tools-zur-forschungsfrage",
    "href": "1_Literaturrecherche.html#explorative-recherche-mit-deep-research-tools-zur-forschungsfrage",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.5 Explorative Recherche mit Deep Research Tools zur Forschungsfrage",
    "text": "1.5 Explorative Recherche mit Deep Research Tools zur Forschungsfrage\n\n1.5.1 Durchführen der Deep Research Recherche\nDie weitergehende Forschung zu diesen beiden Tools noch fehlt, wurde der Report ohne weitere Instruktionen sowohl für Deep Research von Open AI und Deep Research (11.04.2025) direkt verwendet:\n\n\n\n\n\n\nVerwendeter Prompt in Gemini Advanced (Deep Research mit 2.5 Pro) und ChatGPT Deep Research:\n\n\n\n\n\nFühre eine allumfassende Literaturrecherche zum Zusammenhang zwischen kognitiver Anstrengung (cognitive effort) und kognitiver Performance durch. Konzentriere dich dabei primär auf psychologische Studien und Modelle, beziehe aber sämtliche relevante Erkenntnisse aus angrenzenden Disziplinen wie den Kognitions- und Neurowissenschaften, Wirtschaftswissenschaften, Biologie etc. mit ein. Priorisiere bei der Recherche Publikationen aus hochrangigen, peer-reviewten Fachzeitschriften (High-Impact Journals). Die Recherche soll folgende Kernfragen beleuchten: Linearität: Gibt es Evidenz für einen direkten, linearen Zusammenhang zwischen dem Grad der unmittelbaren Anstrengung und dem Niveau der kognitiven Leistung? Nicht-Linearität & optimale Anstrengung: Welche Belege gibt es für nicht-lineare Zusammenhänge (z.B. U-förmig, invers U-förmig)? Unter welchen Umständen führt mehr Anstrengung nicht zu besserer Leistung oder sogar zu einer Leistungsverschlechterung? Moderierende Faktoren: Welche Variablen beeinflussen die Beziehung zwischen Anstrengung und Leistung maßgeblich (z.B. Aufgabenkomplexität, Aufgabentyp, Motivation, individuelle Fähigkeiten, Müdigkeit, Alter, wahrgenommene Selbstwirksamkeit)? Theoretische Grundlagen: Welche etablierten Theorien oder Modelle werden herangezogen, um diesen Zusammenhang zu erklären? Messung: Wie werden ‘momentane kognitive Anstrengung’ und ‘kognitive Performance’ in diesen Studien typischerweise operationalisiert und gemessen? Bitte synthetisiere die wichtigsten Ergebnisse äusserst ausführlich (10000 Seiten) , identifiziere zentrale Debatten oder Forschungslücken und erstelle eine Liste der relevantesten Schlüsselpublikationen (inklusive wichtiger Reviews oder Meta-Analysen). Wenn möglich, gib die Referenzen im APA 7 Format an oder stelle die Informationen so bereit, dass sie leicht in dieses Format überführt werden können. (1) Recherchiere etablierte Definitionen und Konzepte von kognitiver Anstrengung und kognitiver Leistung in der Psychologie, den Kognitions- und Neurowissenschaften sowie sämtlichen angrenzenden relevanten Disziplinen. (2) Suche nach empirischen Studien und Meta-Analysen, die einen linearen Zusammenhang zwischen dem Ausmaß kognitiver Anstrengung und dem Niveau kognitiver Leistung untersuchen. (3) Identifiziere Forschungsarbeiten, die nicht-lineare Beziehungen (z.B. invertierte U-Form) zwischen kognitiver Anstrengung und Leistung belegen, einschließlich Studien zu Phänomenen wie “Choking under Pressure” oder Leistungsabfall bei Überanstrengung. (4) Untersuche Studien, die Moderatoren der Beziehung zwischen kognitiver Anstrengung und Leistung analysieren, darunter: (a) Aufgabenmerkmale (z.B. Komplexität, Typ, Dauer) (b) Individuelle Unterschiede (z.B. Motivation, Fähigkeiten, Alter, Ermüdung, Selbstwirksamkeit) (c) Kontextfaktoren (z.B. Stress, Anreize) (5) Recherchiere zentrale theoretische Modelle, die zur Erklärung des Zusammenhangs zwischen kognitiver Anstrengung und Leistung herangezogen werden. Analysiere ihre Grundannahmen und Vorhersagen. (6) Finde heraus, wie kognitive Anstrengung (z.B. subjektive Bewertungen, physiologische Maße wie Pupillometrie, Herzratenvariabilität, EEG/fMRT) und kognitive Leistung (z.B. Genauigkeit, Reaktionszeit) in der Forschung typischerweise operationalisiert und gemessen werden. (7) Synthetisiere die Ergebnisse der Recherche, identifiziere zentrale wissenschaftliche Debatten, widersprüchliche Befunde und offene Forschungsfragen im Themenbereich. (8) Erstelle eine Liste der Schlüsselpublikationen (einschließlich wichtiger Übersichtsarbeiten und Meta-Analysen) zum Thema und extrahiere die bibliographischen Informationen (Autoren, Jahr, Titel, Zeitschrift, DOI), um eine Formatierung im APA-7-Stil zu ermöglichen.\n\n\n\nRückfrage von Gemini war, beantwortet wurde diese mit “Den besten und umfangreichsten Report, den du anfertigen kannst”:\n\n\n\n\n\n\nChatGPT Deep Research:\n\n\n\n\n\nVielen Dank für den umfassenden Auftrag! Damit ich mit der Recherche beginnen kann:\nGibt es einen bestimmten zeitlichen Rahmen, den du bevorzugst (z.B. Publikationen der letzten 10 oder 20 Jahre)?\nSollen auch deutschsprachige Studien einbezogen werden oder ausschließlich englischsprachige Literatur?\nGibt es spezielle Datenbanken oder Zeitschriften, die du bevorzugst (z.B. Nature Neuroscience, Psychological Review, Science, etc.)?\nMöchtest du die Ergebnisse als Fließtext (z.B. für ein Paper) oder auch in Tabellenform, um Vergleichbarkeit zu erleichtern?\nSobald ich das weiß, starte ich direkt mit der Recherche!\n\n\n\nAnschliessend wurden beide Reports exportiert und abgespeichert. (14.04.2025): (Deep_Research_ChatGPT_Output)"
  },
  {
    "objectID": "1_Literaturrecherche.html#recherche-mit-chatgpt-oder-anderen-tools-unter-berücksichtigung-von-passender-forschungsmethodik",
    "href": "1_Literaturrecherche.html#recherche-mit-chatgpt-oder-anderen-tools-unter-berücksichtigung-von-passender-forschungsmethodik",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.7 Recherche mit ChatGPT oder anderen Tools unter Berücksichtigung von passender Forschungsmethodik",
    "text": "1.7 Recherche mit ChatGPT oder anderen Tools unter Berücksichtigung von passender Forschungsmethodik\nTodo: https://agentlaboratory.github.io/ und ähnliche Papers"
  },
  {
    "objectID": "1_Literaturrecherche.html#aufbereitung-des-textes-und-konvertierung-der-referenzen-in-apa7",
    "href": "1_Literaturrecherche.html#aufbereitung-des-textes-und-konvertierung-der-referenzen-in-apa7",
    "title": "1  Literaturrecherche zur Beziehung von Effort und Performance",
    "section": "1.6 Aufbereitung des Textes und Konvertierung der Referenzen in APA7",
    "text": "1.6 Aufbereitung des Textes und Konvertierung der Referenzen in APA7\nDer entstanden ChatGPT Deep Research Text Output (Deep_Research_ChatGPT_Output_2) wurde in Gemini eingefügt und der folgende Prompt ausgeführt:\n\n\n\n\n\n\nVerwendeter Prompt in Gemini 2.5 Pro (Preview 03-25):\n\n\n\n\n\n«Konvertiere sämtliche Referenzen in diesem Text in die passenden APA7 Zitate und ein passendes Literaturverzeichnis:» Das entstandene Dokument wurde erneut abgespeichert. (Deep_Research_ChatGPT_Output_2)."
  }
]